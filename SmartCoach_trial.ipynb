{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdWKFe+AeNCoJkGxpS94ju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anukriti2001/Anukriti/blob/master/SmartCoach_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing necessary libraries and modules"
      ],
      "metadata": {
        "id": "PtmWJuQ1HFBv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PCKqq5TYllE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #for data manipulation and analysis\n",
        "import numpy as np #for multidimensional arrays\n",
        "import re #for regular expressions\n",
        "from numpy import log\n",
        "import matplotlib.pyplot as plt #for visualization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Activation, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "#from tensorflow.keras.optimizers.legacy import Adam\n",
        "from collections import deque\n",
        "import time\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "mb8rUYiTuRW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym"
      ],
      "metadata": {
        "id": "T_4bmY4nYof-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4d22589-639c-4b62-f36b-1aa78a0f6d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.9/dist-packages (0.21.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_yQyX2H3YpQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3"
      ],
      "metadata": {
        "id": "jK0gX8yiZ6kB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f28bb94-8f9b-4d9e-f8a6-6e13706aad60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.9/dist-packages (1.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (2.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (3.5.3)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (1.13.1+cu116)\n",
            "Requirement already satisfied: gym==0.21 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (0.21.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (1.4.4)\n",
            "Requirement already satisfied: importlib-metadata~=4.13 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata~=4.13->stable-baselines3) (3.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3) (4.5.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (23.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (4.39.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->stable-baselines3) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "State Space : Heart Rate, Systolic Blood Pressure, Diastolic Blood Pressure, Oxygen levels and Calories Burnt\n",
        "\n",
        "Additional data input: Gender, Age, Height, Weight\n",
        "\n",
        "Action Space: Normal treadmill walk(low level), Aerobic treadmill walk(moderate level), High intensity treadmill walk(HIIT level), Treadmill run, Cycling, Rest(Cool down)"
      ],
      "metadata": {
        "id": "MZEgBNTiYuO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gender = 0 for female and 1 for male"
      ],
      "metadata": {
        "id": "ffQ__pGtcqFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gender = np.random.randint(0,3)\n",
        "gender"
      ],
      "metadata": {
        "id": "dmALFAO7cjkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b664efef-c9ba-4118-adea-5a8a3a6687d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "age = np.random.randint(20,70)\n",
        "age"
      ],
      "metadata": {
        "id": "r5K9Y9yw3rak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d223013-7b3b-483a-c096-0faf60454ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight = np.random.randint(50,108)\n",
        "weight"
      ],
      "metadata": {
        "id": "ho4gEqIFUcjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e68c554c-a650-4589-cb19-1ebc371565a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "height = np.random.randint(150,180)\n",
        "height"
      ],
      "metadata": {
        "id": "DdxOelIgYXYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "326a84e3-6490-4495-8a45-93996e771b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "157"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bmi = weight/((height/100) * (height/100))\n",
        "bmi"
      ],
      "metadata": {
        "id": "I_lG3V2cY0bX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56751649-78e3-4bc8-f6e8-b2640d1254b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35.295549515193315"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if(gender == 0):\n",
        "  gd = 3\n",
        "else:\n",
        "  gd = 4"
      ],
      "metadata": {
        "id": "ZufZZRhSigtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining heart rates for different zones"
      ],
      "metadata": {
        "id": "S__lH8pqIPAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#also for 100% intensity(heart rate)\n",
        "max_hr = 211 - (0.64 * age)\n",
        "max_hr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0edMLn7n4Q6j",
        "outputId": "3d02b2ba-a169-4675-b7cc-b117a8bad623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "189.88"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#heart rate\n",
        "general_thr_min = 60\n",
        "general_thr_max = 100\n",
        "safe_zone_min = 0.6 * max_hr\n",
        "safe_zone_max = 0.9 * max_hr\n",
        "walking_thr_min = 0.5 * max_hr\n",
        "walking_thr_max = 0.85 * max_hr\n",
        "walking_aerobic_min = 0.7 * max_hr\n",
        "walking_aerobic_max = 0.8 * max_hr\n",
        "walking_hiit_min = 0.8 * max_hr\n",
        "walking_hiit_max = max_hr\n",
        "running_hiit_min = 0.7 * max_hr\n",
        "running_hiit_max = 0.85 * max_hr\n",
        "cycling_min = 0.5 * max_hr\n",
        "cycling_max = 0.6 * max_hr\n",
        "weightllifting_min = 0.8 * max_hr\n",
        "weightllifting_max = 0.95 * max_hr"
      ],
      "metadata": {
        "id": "ztQyKN1X8nMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining blood pressure for different zones"
      ],
      "metadata": {
        "id": "Ffqo0hb6IWbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#blood pressure\n",
        "normal_sys_max = 120\n",
        "normal_dia_max = 80\n",
        "normal_sys_min = 90\n",
        "normal_dia_min = 60\n",
        "#normal_bp = normal_sys_max & normal_dia_max\n",
        "elevated_sys_min = 120\n",
        "elevated_sys_max = 129\n",
        "elevated_dia_max = 80\n",
        "#elevated_bp = (elevated_sys_min || elevated_sys_max) & elevated_dia_max\n",
        "hyper1_sys_min = 130\n",
        "hyper1_sys_max = 139\n",
        "hyper1_dia_min = 80\n",
        "hyper1_dia_max = 89\n",
        "#hyper1_bp = (hyper1_sys_min || hyper1_sys_max) | (hyper1_dia_min || hyper1_dia_max)\n",
        "hyper2_sys_min = 140\n",
        "hyper2_sys_max = 179\n",
        "hyper2_dia_min = 90\n",
        "hyper2_dia_max = 119\n",
        "#hyper2_bp = (hyper2_sys_min || hyper2_sys_max) | (hyper2_dia_min || hyper2_dia_max)\n",
        "hyper3_sys_min = 180\n",
        "hyper3_dia_min = 120\n",
        "#hyper3_bp = (hyper1_sys_min || hyper1_sys_max) &| (hyper1_dia_min || hyper1_dia_max)\n",
        "exc_sys_min = -4\n",
        "exc_sys_max = -12\n",
        "exc_dia_min = -6\n",
        "exc_dia_max = 9\n",
        "wl_sys_min = -6.7\n",
        "wl_sys_max = -2.8\n",
        "wl_dia_min = -4.9\n",
        "wl_dia_max = -2.1\n",
        "risky_dia_min = +10\n",
        "run_sys_normal_min = 160\n",
        "run_sys_normal_max = 200\n",
        "run_dia_normal = 70 \n",
        "run_sys_risk_min = 225\n",
        "moderate_run_sys_risk_min = 210\n",
        "risky_sys3minstread_syspeak = 0.9\n",
        "#run_rest_bp < pre_exc_level\n",
        "aerobic_walking_min = -5\n",
        "aerobic_walking_max = -7\n",
        "exc_hyper_men_min = 210\n",
        "exc_hyper_women_min = 190\n",
        "risky_dia_min = +10"
      ],
      "metadata": {
        "id": "TY21zmYIKCCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining oxygen levels for different zones"
      ],
      "metadata": {
        "id": "Ffm6-fHwIfZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#spo2\n",
        "normal_spo2_min = 0.95\n",
        "normal_spo2_max = 1.00\n",
        "mild_hypoxia_spo2_min = 0.91\n",
        "mild_hypoxia_spo2_max = 0.94\n",
        "moderate_hypoxia_spo2_min = 0.86\n",
        "moderate_hypoxia_spo2_max = 0.90\n",
        "severe_hypoxia_spo2_max = 0.85\n",
        "\n",
        "hiit_spo2_min = 0.887\n",
        "hiit_spo2_max = 0.95\n",
        "running_spo2_min = -0.02\n",
        "running_spo2_max = -0.03\n",
        "cycling_spo2_min = 0.84\n",
        "cycling_spo2_max = 0.95\n",
        "safe_spo2_min = 0.92\n",
        "safe_spo2_max = 0.99\n",
        "risky_spo2_max = 0.87\n",
        "\n",
        "eih_drop_men = -0.04\n",
        "eih_drop_women = -0.03\n",
        "#with each additional 1% decrement in spO2 resulting in a 1% decrement in VO2max. "
      ],
      "metadata": {
        "id": "aI8f_OaoKDri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vo2max  absolute values\n",
        "vo2_men_normal_min = 35\n",
        "vo2_men_normal_max = 40\n",
        "vo2_women_normal_min = 27\n",
        "vo2_women_normal_max = 30\n",
        "\n",
        "lactate_threshold_min_men = 0.5 * vo2_men_normal_min\n",
        "lactate_threshold_max_men= 0.8 * vo2_men_normal_min\n",
        "lactate_threshold_min_women = 0.5 * vo2_women_normal_min\n",
        "lactate_threshold_max_women= 0.8 * vo2_women_normal_min"
      ],
      "metadata": {
        "id": "69BGSzu9XtB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vo2 table men\n",
        "\n",
        "#max = upper min - 1\n",
        "\n",
        "vo2_men_exc_min = (-0.4879 * age) + 68.5\n",
        "vo2_men_good_max = vo2_men_exc_min - 1\n",
        "vo2_men_good_min = (-0.40524 * age) + 58.75\n",
        "vo2_men_aboveavg_max = vo2_men_good_min - 1 \n",
        "vo2_men_aboveavg_min = (-0.36976 * age) + 52.95 \n",
        "vo2_men_avg_max = vo2_men_aboveavg_min - 1\n",
        "vo2_men_avg_min = (-0.33226 * age) + 47.9 \n",
        "vo2_men_belowavg_max = vo2_men_avg_min - 1\n",
        "vo2_men_belowavg_min = (-0.30605 * age) + 42.65 \n",
        "vo2_men_poor_max = vo2_men_belowavg_min - 1\n",
        "vo2_men_poor_min = (-0.22137 * age) + 34.65 \n",
        "vo2_men_vpoor_max = (-0.22137 * age) + 34.65 "
      ],
      "metadata": {
        "id": "7DaXBSU_khh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vo2 table women\n",
        "vo2_women_exc_min = (-0.49919 * age) + 64.3\n",
        "vo2_women_good_max = vo2_women_exc_min - 1 \n",
        "vo2_women_good_min = (-0.40565 * age) + 54.1 \n",
        "vo2_women_aboveavg_max = vo2_women_good_min - 1 \n",
        "vo2_women_aboveavg_min = (-0.35524 * age) + 47.85 \n",
        "vo2_women_avg_max = vo2_women_aboveavg_min - 1\n",
        "vo2_women_avg_min = (-0.33185 * age) + 43.55 \n",
        "vo2_women_belowavg_max = vo2_women_avg_min - 1\n",
        "vo2_women_belowavg_min = (-0.29113 * age) + 38.2 \n",
        "vo2_women_poor_max = vo2_women_belowavg_min - 1\n",
        "vo2_women_poor_min = (-0.2375 * age) + 31.65 \n",
        "vo2_women_vpoor_max = (-0.2375 * age) + 31.65"
      ],
      "metadata": {
        "id": "Mbk5wRrpm-jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining calories burnt per half hour for different zones"
      ],
      "metadata": {
        "id": "O6Je95zZIu6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calories\n",
        "#half hour\n",
        "aerobic_cycling_women = 202\n",
        "aerobic_cycling_men = 225\n",
        "hiit_cycling_women = 314\n",
        "hiit_cycling_men = 358 \n",
        "run_min = 250\n",
        "run_max = 500\n",
        "cycle_min = 50\n",
        "cycle_max = 325\n",
        "\n",
        "#dist_km = 23 * dist\n",
        "rmr_women = (9.99 * weight) + (6.25 * height) - (4.92 * age) - 161\n",
        "rmr_men = (9.99 * weight) + (6.25 * height) - (4.92 * age) + 5\n",
        "pal_little_no_exc = 1.2\n",
        "pal_light_exc = 1.375\n",
        "pal_moderate_exc = 1.55\n",
        "pal_heavy_exc = 1.725\n",
        "pal_very_heavy_exc = 2\n",
        "cal_walk_min = 92\n",
        "cal_walk_max = 250\n",
        "cal_aerobic_walking = 129\n",
        "cal_running = 340\n",
        "cal_running_5miles = 292\n",
        "cal_running_8miles = 493\n",
        "normal_walk_mets = 3\n",
        "aerobic_walk_mets = 4\n",
        "hiit_walk_mets = 5\n",
        "run_mets = 10\n",
        "cycle_mets = 8\n",
        "weightlifting_mets = 6"
      ],
      "metadata": {
        "id": "yzErJ5_2KGBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calory table\n",
        "cal_cycle_women = (0.89391 * weight) + 25.53454\n",
        "cal_aerobic_cycle_women = (0.0752 * weight) + 211.95333\n",
        "cal_hiit_cycle_women = (4.12807 * weight) + 24.11874\n",
        "\n",
        "cal_cycle_men = (0.64169 * weight) + 38.99398 \n",
        "cal_aerobic_cycle_men = (2.25734 * weight) + 38.25237\n",
        "cal_hiit_cycle_men = (3.85403 * weight) + 39.57848\n",
        "\n",
        "\n",
        "cal_run_5mph = (4.10296 * weight) - 8.35063\n",
        "cal_run_6mph = (5.12931 * weight) - 10.60965\n",
        "cal_run_7mph = (5.84921 * weight) - 8.50223\n",
        "cal_run_8mph = (6.87556 * weight) - 10.76125\n",
        "cal_run_9mph = (7.40454 * weight) + 3.65383\n",
        "cal_run_10mph = (8.18889 * weight) - 15.90312"
      ],
      "metadata": {
        "id": "x2YyGrjcUmVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial state"
      ],
      "metadata": {
        "id": "58JEXsTQI7lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state = {\n",
        "    'heartrate' : np.random.uniform(general_thr_min, general_thr_max),\n",
        "    'sys_bp': np.random.uniform(normal_sys_min, normal_sys_max),\n",
        "    'dia_bp': np.random.uniform(normal_dia_min, normal_dia_max),\n",
        "    'spo2' : np.random.uniform(normal_spo2_min, normal_spo2_max),\n",
        "    #'vo2' : np.random.uniform(9 * gd, 10 * gd),\n",
        "    'calories_burnt' : 0,\n",
        "    'duration_mins' : 0\n",
        "}"
      ],
      "metadata": {
        "id": "HQG1dSPbY7RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state"
      ],
      "metadata": {
        "id": "4Hds1v2YxIl_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "102390ed-0038-47c4-a808-998a69f01ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'heartrate': 72.08816239775976,\n",
              " 'sys_bp': 92.53674503679757,\n",
              " 'dia_bp': 63.43233295549411,\n",
              " 'spo2': 0.9881275775882387,\n",
              " 'calories_burnt': 0,\n",
              " 'duration_mins': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_sys = state['sys_bp']\n",
        "initial_spo2 = state['spo2']"
      ],
      "metadata": {
        "id": "mesSCFCjQpne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Normal treadmill walk"
      ],
      "metadata": {
        "id": "Nf9i3dlBJAa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def walk(state):\n",
        "  state['duration_mins'] = np.random.randint(0,30)\n",
        "  state['heartrate'] = np.random.uniform(walking_thr_min, walking_thr_max)\n",
        "  #state['heartrate'] += np.random.uniform(walking_thr_min - state['heartrate'], walking_thr_max - state['heartrate'])\n",
        "  state['sys_bp'] += np.random.uniform(5,10) * normal_walk_mets\n",
        "  state['dia_bp'] += np.random.uniform(exc_dia_min,exc_dia_max)\n",
        "  state['spo2'] += np.random.uniform(safe_spo2_min, safe_spo2_max)\n",
        "  #state['vo2'] = 56.363 + (1.921 * pal_light_exc) - (0.381 * age) - (0.754 * bmi) + (10.987 * gender)\n",
        "  #state['calories_burnt'] += np.random.uniform(cal_walk_min,cal_walk_max)\n",
        "  state['calories_burnt'] += state['duration_mins'] * (normal_walk_mets * 3.5 * weight)/200\n",
        "  #state['calories_burnt'] += (63 * dist_miles) - 72\n",
        "  return state"
      ],
      "metadata": {
        "id": "4GOLVaMJZNeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = walk(state)\n",
        "state"
      ],
      "metadata": {
        "id": "e1C6fOV8ZXdZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7ef487-b9b3-499d-9ed5-4430deedc7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'heartrate': 105.40659990151269,\n",
              " 'sys_bp': 115.42840098584296,\n",
              " 'dia_bp': 66.11613457377614,\n",
              " 'spo2': 1.92188066774565,\n",
              " 'calories_burnt': 4.926108374384237e-05,\n",
              " 'duration_mins': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Aerobic treadmill walk"
      ],
      "metadata": {
        "id": "g5jJDhZOJH45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def aerobic_walk(state):\n",
        "  state['duration_mins'] = np.random.randint(0,30)\n",
        "  state['heartrate'] = np.random.uniform(walking_aerobic_min, walking_aerobic_max)\n",
        "  #state['sys_bp'] -= np.random.uniform(aerobic_walking_min, aerobic_walking_max)\n",
        "  state['sys_bp'] += np.random.uniform(5,10) * aerobic_walk_mets\n",
        "  state['dia_bp'] += np.random.uniform(exc_dia_min,exc_dia_max)\n",
        "  state['spo2'] += np.random.uniform(safe_spo2_min, safe_spo2_max)\n",
        "  #state['vo2'] = 56.363 + (1.921 * pal_moderate_exc) - (0.381 * age) - (0.754 * bmi) + (10.987 * gender)\n",
        "  #state['calories_burnt'] = np.random.uniform(,)\n",
        "  state['calories_burnt'] += state['duration_mins'] * (aerobic_walk_mets * 3.5 * weight)/200\n",
        "  return state"
      ],
      "metadata": {
        "id": "LJmL1pTLu0Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = aerobic_walk(state)\n",
        "state"
      ],
      "metadata": {
        "id": "LD3Y7SPiu4rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26850518-44c2-472c-98f8-5e0457498f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'heartrate': 150.78930983886895,\n",
              " 'sys_bp': 144.27059747825956,\n",
              " 'dia_bp': 64.86645139326349,\n",
              " 'spo2': 2.8985851176240782,\n",
              " 'calories_burnt': 9.669768290457946e-05,\n",
              " 'duration_mins': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining HIIT treadmill walk"
      ],
      "metadata": {
        "id": "1mscpPahJLjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hiit_walk(state):\n",
        "  state['duration_mins'] = np.random.randint(0,30)\n",
        "  state['heartrate'] = np.random.uniform(walking_hiit_min, walking_hiit_max)\n",
        "  state['sys_bp'] += np.random.uniform(5,10) * hiit_walk_mets\n",
        "  state['dia_bp'] += np.random.uniform(exc_dia_min,exc_dia_max)\n",
        "  state['spo2'] += np.random.uniform(hiit_spo2_min, hiit_spo2_max)\n",
        "  #state['vo2'] -= np.random.uniform(hiit_vo2_min,hiit_vo2_max)\n",
        "  #state['vo2'] = 56.363 + (1.921 * pal_heavy_exc) - (0.381 * age) - (0.754 * bmi) + (10.987 * gender)\n",
        "  #state['calories_burnt'] = np.random.uniform(,)\n",
        "  state['calories_burnt'] += state['duration_mins'] * (hiit_walk_mets * 3.5 * weight)/200\n",
        "  return state"
      ],
      "metadata": {
        "id": "U6o3P8tMvFa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = hiit_walk(state)\n",
        "state"
      ],
      "metadata": {
        "id": "YwBSBW8xvNUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9408de2-9895-4120-848f-e86ba76953c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'heartrate': 174.60294685500884,\n",
              " 'sys_bp': 174.96454748867265,\n",
              " 'dia_bp': 67.7207499995793,\n",
              " 'spo2': 3.803640392500599,\n",
              " 'calories_burnt': 0.00011311804415252691,\n",
              " 'duration_mins': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining treadmill run"
      ],
      "metadata": {
        "id": "a0myCFYVJPin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run(state):\n",
        "  state['duration_mins'] = np.random.randint(0,30)\n",
        "  state['heartrate'] = np.random.uniform(running_hiit_min, running_hiit_max)\n",
        "  state['sys_bp'] = np.random.uniform(run_sys_normal_min, run_sys_normal_max)\n",
        "  state['dia_bp'] += np.random.uniform(exc_dia_min,exc_dia_max)\n",
        "  state['spo2'] += np.random.uniform(running_spo2_min, running_spo2_min)\n",
        "  #state['vo2'] = 56.363 + (1.921 * pal_very_heavy_exc) - (0.381 * age) - (0.754 * bmi) + (10.987 * gender)\n",
        "  #state['calories_burnt'] = np.random.uniform(,)\n",
        "  state['calories_burnt'] += state['duration_mins'] * (run_mets * 3.5 * weight)/200\n",
        "  return state"
      ],
      "metadata": {
        "id": "DradNUqNZYmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = run(state)\n",
        "state"
      ],
      "metadata": {
        "id": "u7SKvDgmZanR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d896ee8-f16d-4911-d526-380b91a32f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'heartrate': 133.22004768995694,\n",
              " 'sys_bp': 196.38365658561042,\n",
              " 'dia_bp': 65.09132022410088,\n",
              " 'spo2': 3.783640392500599,\n",
              " 'calories_burnt': 0.0001623791278963693,\n",
              " 'duration_mins': 21}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining cycling"
      ],
      "metadata": {
        "id": "IpS5_DSoJT3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cycle(state):\n",
        "  state['duration_mins'] = np.random.randint(0,30)\n",
        "  state['heartrate'] = np.random.uniform(cycling_min, cycling_max)\n",
        "  state['sys_bp'] = np.random.uniform(run_sys_normal_max, run_sys_normal_max)\n",
        "  state['dia_bp'] += np.random.uniform(exc_dia_min,exc_dia_max)\n",
        "  state['spo2'] += np.random.uniform(cycling_spo2_min, cycling_spo2_max)\n",
        "  #state['vo2'] = 56.363 + (1.921 * pal_very_heavy_exc) - (0.381 * age) - (0.754 * bmi) + (10.987 * gender)\n",
        "  #state['calories_burnt'] = np.random.uniform(,)\n",
        "  state['calories_burnt'] += state['duration_mins'] * (cycle_mets * 3.5 * weight)/200\n",
        "  #state['calories_burnt'] = (21.76734 * speed_mph) - 179.2953\n",
        "  return state"
      ],
      "metadata": {
        "id": "W20iFvaFZb2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = cycle(state)\n",
        "state"
      ],
      "metadata": {
        "id": "ZcQs2zVWehZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e398a97-b4bb-4f3a-d768-7ed6e2d3160a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'heartrate': 104.49497686925166,\n",
              " 'sys_bp': 200.0,\n",
              " 'dia_bp': 73.91258526376424,\n",
              " 'spo2': 4.654675579498429,\n",
              " 'calories_burnt': 0.0001685367633643496,\n",
              " 'duration_mins': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#heart rate\n",
        "heartrate_drop_min = 15\n",
        "heartrate_drop_max = 20\n",
        "heartrate_drop_risky_max = 12\n",
        "\n",
        "#blood pressure\n",
        "sysbp_risky = +5\n",
        "sysbp_risky_min = 190\n",
        "diabp_risky_min = 110\n",
        "sysbp_men_max = -64\n",
        "sysbp_men_min = -44\n",
        "\n",
        "#vo2\n",
        "\n",
        "#calories for 1 hour\n",
        "rest_aerobic_hiit_cal_min = 15\n",
        "rest_aerobic_hiit_cal_min = 20\n",
        "rest_run_cycle_cal_min = 23\n",
        "rest_run_cycle_cal_min = 33"
      ],
      "metadata": {
        "id": "LzpOuvWPNfHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Weight Lifting"
      ],
      "metadata": {
        "id": "QEFOrl7WEW-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  men: [Minutes working out] × [Bodyweight in kg] × 0.0713\n",
        "Women: [Minutes working out] × [Bodyweight in kg] × 0.0637\n",
        "\n",
        "https://www.strengthlog.com/calories-burned-lifting-weights/\n",
        "\n",
        "By multiplying the body weight in kg by the MET (*) value and duration of activity, you can estimate the energy expenditure in Kcal specific to a persons body weight. In this example, weight lifting at a 6 MET value, burns 6 Kcal/kg x body weight/h.\n",
        "\n",
        "A 70 kg individual weight lifting for 30 minutes expends the following:\n",
        "\n",
        "(6 METs x 70 kg body weight) x (30 min/60 min) = 210.0 Kcal.\n",
        "SOME divide this by 200\n",
        "\n",
        "https://coolconversion.com/calories-burned/Calorie-Calculator-%7C-_weight-lifting_\n",
        "\n",
        "The formula to use is: METs x 3.5 x (your body weight in kilograms) / 200 = calories burned per minute."
      ],
      "metadata": {
        "id": "EkpaAqT-x0B2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weightlift(state):\n",
        "  state['duration_mins'] = np.random.randint(0,30)\n",
        "  state['heartrate'] = np.random.uniform(weightllifting_min, weightllifting_max)\n",
        "  state['sys_bp'] += np.random.uniform(wl_sys_min,wl_sys_max)\n",
        "  state['dia_bp'] += np.random.uniform(wl_dia_min,wl_dia_max)\n",
        "  state['spo2'] += np.random.uniform(hiit_spo2_min, hiit_spo2_max)\n",
        "  #state['vo2'] = 56.363 + (1.921 * pal_very_heavy_exc) - (0.381 * age) - (0.754 * bmi) + (10.987 * gender)\n",
        "  state['calories_burnt'] += state['duration_mins'] * (cycle_mets * 3.5 * weight)/200\n",
        "  return state"
      ],
      "metadata": {
        "id": "G3jhUPA3EZuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = weightlift(state)\n",
        "state"
      ],
      "metadata": {
        "id": "sCh3Fjy-EaQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining rest/cool down"
      ],
      "metadata": {
        "id": "MQnkOIBQJgDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rest(state): #per minute\n",
        "  state['duration_mins'] = np.random.randint(5,10)\n",
        "  state['heartrate'] -= np.random.uniform(heartrate_drop_min, heartrate_drop_max)\n",
        "  state['sys_bp'] = initial_sys - np.random.uniform(sysbp_men_min, sysbp_men_max)\n",
        "  state['spo2'] += np.random.uniform(normal_spo2_min, normal_spo2_max)\n",
        "  #state['vo2'] = ((220 - age)/state['heartrate']) * 15\n",
        "  state['calories_burnt'] += np.random.uniform(0.06,0.15) * state['calories_burnt']\n",
        "  return state"
      ],
      "metadata": {
        "id": "XEm71qtUbEsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = rest(state)\n",
        "state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7Nc1RTG4zku",
        "outputId": "56401f00-ef80-4764-ad85-5e5a13566f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'heartrate': 85.0207135097973,\n",
              " 'sys_bp': 149.76083754719298,\n",
              " 'dia_bp': 73.91258526376424,\n",
              " 'spo2': 5.63470090385151,\n",
              " 'calories_burnt': 0.00019062493740597275,\n",
              " 'duration_mins': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Action space"
      ],
      "metadata": {
        "id": "crjrHH7tJuA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actions = [rest, walk, aerobic_walk, hiit_walk, run, cycle, weightlift]"
      ],
      "metadata": {
        "id": "vqypJWDpa4q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smartcoach_action_space = gym.spaces.Discrete(len(actions))"
      ],
      "metadata": {
        "id": "AZIAsXpIbDkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Safe lower and upper bounds"
      ],
      "metadata": {
        "id": "QxSjd7sxJyA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "observations = ['heartrate','sys_bp','dia_bp','spo2', 'calories_burnt']\n",
        "\n",
        "def make_smartcoach_obs_space():\n",
        "    lower_obs_bound = {\n",
        "        'heartrate' : safe_zone_min,\n",
        "        'sys_bp' : normal_sys_min,\n",
        "        'dia_bp': normal_dia_min,\n",
        "        'spo2' : safe_spo2_min,\n",
        "        #'vo2' : 9 * gd,\n",
        "        'calories_burnt' : 0,\n",
        "        'duration_mins' : 0\n",
        "    }\n",
        "    higher_obs_bound = {\n",
        "        'heartrate' : safe_zone_max,\n",
        "        'sys_bp' : normal_sys_max,\n",
        "        'dia_bp' : normal_dia_max,\n",
        "        'spo2' : safe_spo2_max,\n",
        "        #'vo2' : 10 * gd,\n",
        "        'calories_burnt' : 500,\n",
        "        'duration_mins' : 30\n",
        "    }\n",
        "\n",
        "    low = np.array([lower_obs_bound[o] for o in observations])\n",
        "    high = np.array([higher_obs_bound[o] for o in observations])\n",
        "    shape = (len(observations),)\n",
        "    return gym.spaces.Box(low,high,shape)"
      ],
      "metadata": {
        "id": "9-K64h5RZvxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining how different conditions can affect the risk of heart attack "
      ],
      "metadata": {
        "id": "9KALUgIsM_TY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Risky conditions\n",
        "def risky_conditions(state):\n",
        "  heart_rate = (state['heartrate'] < safe_zone_min) or ((state['heartrate'] > safe_zone_max))\n",
        "  sys_bp = (state['sys_bp'] > hyper1_sys_min) or (state['sys_bp'] < normal_sys_min)\n",
        "  dia_bp = (state['dia_bp'] > hyper1_dia_min) or (state['dia_bp'] < normal_dia_min)\n",
        "  if(gender == 1):\n",
        "    spo2 = ((initial_spo2 - state['spo2']) > 0.04) or (state['spo2'] <= risky_spo2_max)\n",
        "    #vo2 = (state['vo2'] >= lactate_threshold_min_men) or (state['vo2'] <= lactate_threshold_max_men) or (state['vo2'] < vo2_men_poor_max) \n",
        "  else:\n",
        "    spo2 = ((initial_spo2 - state['spo2']) > 0.03) or (state['spo2'] <= risky_spo2_max)\n",
        "    #vo2 = (state['vo2'] >= lactate_threshold_min_women) or (state['vo2'] <= lactate_threshold_max_women) or (state['vo2'] < vo2_women_poor_max)\n",
        "  return (heart_rate or sys_bp or dia_bp or spo2)"
      ],
      "metadata": {
        "id": "CGoKBIrsMnkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Returning whether or not heart attack occured"
      ],
      "metadata": {
        "id": "m6X8LLOUM5xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart_attack_occured = risky_conditions(state)"
      ],
      "metadata": {
        "id": "MEjtZpwqLzx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heart_attack_occured"
      ],
      "metadata": {
        "id": "pvOar75CL6vX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7d94507-a655-4968-a59f-88c9e8a9cfa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SmartCoach(gym.Env):\n",
        "    def __init__(self, heart_attack_proclivity=0.5, max_steps=1000):\n",
        "        self.actions = actions\n",
        "        self.observations = observations\n",
        "        self.action_space = smartcoach_action_space\n",
        "        self.observation_space = make_smartcoach_obs_space()\n",
        "        self.heart_attack_proclivity = heart_attack_proclivity\n",
        "        self.log = ''\n",
        "        self.max_steps = max_steps\n",
        "        \n",
        "    def observation(self):\n",
        "        return np.array([self.state[o] for o in self.observations])\n",
        "        \n",
        "    def reset(self):\n",
        "        self.state = {\n",
        "                'heartrate' : np.random.uniform(general_thr_min, general_thr_max),\n",
        "                'sys_bp': np.random.uniform(normal_sys_min, normal_sys_max),\n",
        "                'dia_bp': np.random.uniform(normal_dia_min, normal_dia_max),\n",
        "                'spo2' : np.random.uniform(normal_spo2_min, normal_spo2_max),\n",
        "                # 'vo2' : np.random.uniform(normal_vo2_min, normal_vo2_min),\n",
        "                'calories_burnt' : 0,\n",
        "                'duration_mins' : 0 \n",
        "        }\n",
        "        self.steps_left = self.max_steps\n",
        "        return self.observation()\n",
        "        \n",
        "    def step(self, action):\n",
        "        if (self.state['duration_mins'] == 0):\n",
        "            old_score = 0\n",
        "        else:\n",
        "            old_score = self.state['calories_burnt'] / self.state['duration_mins']\n",
        "        \n",
        "        # Do selected action\n",
        "        self.actions[action](self.state)\n",
        "        self.log += f'Chosen action: {self.actions[action].__name__}\\n'\n",
        "        if (self.state['duration_mins'] == 0):\n",
        "            new_score = old_score\n",
        "        else: \n",
        "          new_score = self.state['calories_burnt'] / self.state['duration_mins']\n",
        "        reward = new_score - old_score\n",
        "        \n",
        "        #if heart_attack_occured(self.state, self.heart_attack_proclivity):\n",
        "        if heart_attack_occured:\n",
        "          self.log += f'HEART ATTACK\\n'\n",
        "          # We would like to avoid this\n",
        "          reward -= 100\n",
        "            \n",
        "        self.log += str(self.state) + '\\n'\n",
        "        \n",
        "        self.steps_left -= 1\n",
        "        done = (self.steps_left <= 0)\n",
        "        \n",
        "        return self.observation(), reward, done, {}\n",
        "    \n",
        "    def close(self):\n",
        "        pass\n",
        "        \n",
        "    def render(self, mode=None):\n",
        "        print(self.log)\n",
        "        self.log = ''"
      ],
      "metadata": {
        "id": "yKYb0vMT57IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smartcoach = SmartCoach()"
      ],
      "metadata": {
        "id": "1LOV00rUZzjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smartcoach"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMvdJLo1i80T",
        "outputId": "525edde3-b9b1-4315-c097-67751cdf274f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.SmartCoach at 0x7f39a57e2760>"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Q Network"
      ],
      "metadata": {
        "id": "R8quLCkzY1ID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import DQN\n",
        "\n",
        "model = DQN(\"MlpPolicy\", smartcoach, verbose=1, policy_kwargs={'net_arch': [16,16]})"
      ],
      "metadata": {
        "id": "_0iHnHbfZ7At",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdfde5f3-ad88-4ecd-af6b-87490c63ad10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''model.learn(total_timesteps=500000, log_interval=10)'''"
      ],
      "metadata": {
        "id": "8ax-2NEZZ-Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.learn(total_timesteps=100000, log_interval=10)"
      ],
      "metadata": {
        "id": "TjhAy7HXkLcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "mean_reward, std_reward = evaluate_policy(model, smartcoach, n_eval_episodes=5)\n",
        "print(f'Reward per episode {mean_reward} ± {std_reward}')"
      ],
      "metadata": {
        "id": "XhfyguE_aGF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs = smartcoach.reset()\n",
        "total_reward = 0\n",
        "for step in range(10):\n",
        "    action, _states = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, info = smartcoach.step(action)\n",
        "    smartcoach.render()"
      ],
      "metadata": {
        "id": "Ey5GshlGaIGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smartcoach.observation()"
      ],
      "metadata": {
        "id": "sobhHysw0Nfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reward"
      ],
      "metadata": {
        "id": "-PFsSbKj0c9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action"
      ],
      "metadata": {
        "id": "BdXtWNJL0ShC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A2C Model"
      ],
      "metadata": {
        "id": "5W9WtiXxSNgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import A2C"
      ],
      "metadata": {
        "id": "KLs0ZU_3SZdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = A2C(\"MlpPolicy\", smartcoach, verbose = 1)"
      ],
      "metadata": {
        "id": "K4YEIVC2SP9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving and loading models\n",
        "models_dir = \"models/A2C\"\n",
        "logdir = \"logs\"\n",
        "\n",
        "if not os.path.exists(models_dir):\n",
        "  os.makedirs(models_dir)\n",
        "\n",
        "if not os.path.exists(logdir):\n",
        "  os.makedirs(logdir)"
      ],
      "metadata": {
        "id": "KZmKlq1DWtUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = A2C(\"MlpPolicy\", smartcoach, verbose = 1, tensorboard_log = logdir)"
      ],
      "metadata": {
        "id": "PcxAuf4oYkog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TIMESTEPS = 10000"
      ],
      "metadata": {
        "id": "JqoOljhFY40Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(30):\n",
        "  model.learn(total_timesteps = TIMESTEPS, log_interval=10)"
      ],
      "metadata": {
        "id": "Mt1KmBr4-kZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "mean_reward, std_reward = evaluate_policy(model, smartcoach, n_eval_episodes=5)\n",
        "print(f'Reward per episode {mean_reward} ± {std_reward}')"
      ],
      "metadata": {
        "id": "dj96IBPG_DaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''for i in range(30):\n",
        "  model.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name = \"A2C\")\n",
        "  model.save(f\"{models_dir}/{TIMESTEPS * i}\")\n",
        "  '''"
      ],
      "metadata": {
        "id": "tko6zMC8Y8sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tensorboard--logdir = logs"
      ],
      "metadata": {
        "id": "zPU45BJkbLxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 10\n",
        "\n",
        "for ep in range(episodes):\n",
        "  obs = smartcoach.reset()\n",
        "  done = False\n",
        "  while not done:\n",
        "    smartcoach.render()\n",
        "    #obs, reward, done, info = env.step(env.action_space.sample())\n",
        "    #obs, reward, done, info = smartcoach.step(action)\n",
        "\n",
        "  smartcoach.close()"
      ],
      "metadata": {
        "id": "3U6lJJ5JSkWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.learn(total_timesteps = TIMESTEPS)"
      ],
      "metadata": {
        "id": "C-46rL0gT4_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PPO model"
      ],
      "metadata": {
        "id": "1ncz5GrNV0xH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO"
      ],
      "metadata": {
        "id": "76BRBAGo_Nwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PPO(\"MlpPolicy\", smartcoach, verbose = 1)"
      ],
      "metadata": {
        "id": "SeD8Gj5dOu36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec8f969-8e23-4066-c9ad-657fea3f4bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving and loading models\n",
        "models_dir = \"models/PPO\"\n",
        "logdir = \"logs\"\n",
        "\n",
        "if not os.path.exists(models_dir):\n",
        "  os.makedirs(models_dir)\n",
        "\n",
        "if not os.path.exists(logdir):\n",
        "  os.makedirs(logdir)"
      ],
      "metadata": {
        "id": "QUtb4414OzBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PPO(\"MlpPolicy\", smartcoach, verbose = 1, tensorboard_log = logdir)"
      ],
      "metadata": {
        "id": "RSMoO6AdKHIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TIMESTEPS = 10000"
      ],
      "metadata": {
        "id": "_fI8NLXfO92Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(30):\n",
        "  model.learn(total_timesteps = 10000, log_interval=10)"
      ],
      "metadata": {
        "id": "xNBxi-ujO-4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "mean_reward, std_reward = evaluate_policy(model, smartcoach, n_eval_episodes=5)\n",
        "print(f'Reward per episode {mean_reward} ± {std_reward}')"
      ],
      "metadata": {
        "id": "vNoTWtKhPBnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7263351d-0231-46ef-fb0a-3dccc0044738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward per episode -99999.85248565674 ± 0.03295745810754178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''for i in range(30):\n",
        "  model.learn(total_timesteps = TIMESTEPS, reset_num_timesteps = False, tb_log_name = \"A2C\")\n",
        "  model.save(f\"{models_dir}/{TIMESTEPS * i}\")"
      ],
      "metadata": {
        "id": "gh33TqnoPF26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tensorboard--logdir = logs"
      ],
      "metadata": {
        "id": "vSTQAvGsPIrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 10\n",
        "\n",
        "for ep in range(episodes):\n",
        "  obs = smartcoach.reset()\n",
        "  done = False\n",
        "  while not done:\n",
        "    smartcoach.render()\n",
        "    #obs, reward, done, info = env.step(env.action_space.sample())\n",
        "    #obs, reward, done, info = smartcoach.step(action)\n",
        "\n",
        "  smartcoach.close()"
      ],
      "metadata": {
        "id": "xnI1Z7SkPSt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*******\n",
        "Customised Deep Q network"
      ],
      "metadata": {
        "id": "AOLp9VxbKxyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential, layers\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense\n",
        "from collections import deque\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "C-EEsumXJ1Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REPLAY_MEMORY_SIZE = 50000 # How many last steps to keep for model training\n",
        "MIN_REPLAY_MEMORY_SIZE = 1000 # Minimum number of steps in a memory to start training\n",
        "MINIBATCH_SIZE = 64 # How many steps (samples) to use for training\n",
        "DISCOUNT = 0.99\n",
        "UPDATE_TARGET_EVERY = 5\n",
        "MIN_REWARD = -200  # For model save\n",
        "MEMORY_FRACTION = 0.20\n",
        "\n",
        "# Environment settings\n",
        "EPISODES = 20_000\n",
        "\n",
        "# Exploration settings\n",
        "epsilon = 1  # not a constant, going to be decayed\n",
        "EPSILON_DECAY = 0.99975\n",
        "MIN_EPSILON = 0.001\n",
        "\n",
        "#  Stats settings\n",
        "AGGREGATE_STATS_EVERY = 50  # episodes\n",
        "SHOW_PREVIEW = False"
      ],
      "metadata": {
        "id": "f9Na5KyXuqDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class sc:\n",
        "  #CHANGE TO SELF FORM \n",
        "  def __init__(self):\n",
        "    self.state.heartrate = np.random.uniform(general_thr_min, general_thr_max)\n",
        "    self.state.sys_bp = np.random.uniform(normal_sys_min, normal_sys_max)\n",
        "    self.state.dia_bp = np.random.uniform(normal_dia_min, normal_dia_max)\n",
        "    self.state.spo2 = np.random.uniform(normal_spo2_min, normal_spo2_max)\n",
        "    #self.state.vo2 = np.random.uniform(9 * gd, 10 * gd)\n",
        "    self.state.calories_burnt = 0\n",
        "    self.state.duration_mins = 0\n",
        "\n",
        "    self.state.initial_sys = self.state.sys_bp\n",
        "    self.state.initial_spo2 = self.state.spo2\n",
        "\n",
        "    state = {\n",
        "                'heartrate' : np.random.uniform(general_thr_min, general_thr_max),\n",
        "                'sys_bp': np.random.uniform(normal_sys_min, normal_sys_max),\n",
        "                'dia_bp': np.random.uniform(normal_dia_min, normal_dia_max),\n",
        "                'spo2' : np.random.uniform(normal_spo2_min, normal_spo2_max),\n",
        "                # 'vo2' : np.random.uniform(9 * gd, 10 * gd),\n",
        "                'calories_burnt' : 0,\n",
        "                'duration_mins' : 0 \n",
        "        }\n",
        "\n",
        "\n",
        "  #initial_sys = state['sys_bp']\n",
        "  #initial_spo2 = state['spo2']\n",
        "\n",
        "  #NOTE: CHANGE TO SELF FORM\n",
        "\n",
        "  #def walk(self):\n",
        "  # self.duration_mins = np.random.randint(0,30)\n",
        "\n",
        "\n",
        "  def walk(state):\n",
        "    state['duration_mins'] = np.random.randint(0,30)\n",
        "    state['heartrate'] = np.random.uniform(walking_thr_min, walking_thr_max)\n",
        "    #state['heartrate'] += np.random.uniform(walking_thr_min - state['heartrate'], walking_thr_max - state['heartrate'])\n",
        "    state['sys_bp'] += np.random.uniform(5,10) * normal_walk_mets\n",
        "    state['dia_bp'] += np.random.uniform(exc_dia_min,exc_dia_max)\n",
        "    state['spo2'] += np.random.uniform(safe_spo2_min, safe_spo2_max)\n",
        "    #state['vo2'] = 56.363 + (1.921 * pal_light_exc) - (0.381 * age) - (0.754 * bmi) + (10.987 * gender)\n",
        "    #state['calories_burnt'] += np.random.uniform(cal_walk_min,cal_walk_max)\n",
        "    state['calories_burnt'] += state['duration_mins']/(normal_walk_mets * 3.5 * weight)/200\n",
        "    #state['calories_burnt'] += (63 * dist_miles) - 72\n",
        "    return state\n",
        "\n",
        "  def aerobic_walk(state):\n",
        "    state['duration_mins'] = np.random.randint(0,30)\n",
        "    state['heartrate'] = np.random.uniform(walking_aerobic_min, walking_aerobic_max)\n",
        "    #state['sys_bp'] -= np.random.uniform(aerobic_walking_min, aerobic_walking_max)\n",
        "    state['sys_bp'] += np.random.uniform(5,10) * aerobic_walk_mets\n",
        "    state['dia_bp'] += np.random.uniform(exc_dia_min,exc_dia_max)\n",
        "    state['spo2'] += np.random.uniform(safe_spo2_min, safe_spo2_max)\n",
        "    #state['vo2'] = 56.363 + (1.921 * pal_moderate_exc) - (0.381 * age) - (0.754 * bmi) + (10.987 * gender)\n",
        "    #state['calories_burnt'] = np.random.uniform(,)\n",
        "    state['calories_burnt'] += state['duration_mins']/(aerobic_walk_mets * 3.5 * weight)/200\n",
        "    return state\n",
        "\n",
        "  def hiit_walk(state):\n",
        "    state['duration_mins'] = np.random.randint(0,30)\n",
        "    state['heartrate'] = np.random.uniform(walking_hiit_min, walking_hiit_max)\n",
        "    state['sys_bp'] += np.random.uniform(5,10) * hiit_walk_mets\n",
        "    state['dia_bp'] += np.random.uniform(exc_dia_min,exc_dia_max)\n",
        "    state['spo2'] += np.random.uniform(hiit_spo2_min, hiit_spo2_max)\n",
        "    #state['vo2'] -= np.random.uniform(hiit_vo2_min,hiit_vo2_max)\n",
        "    #state['vo2'] = 56.363 + (1.921 * pal_heavy_exc) - (0.381 * age) - (0.754 * bmi) + (10.987 * gender)\n",
        "    #state['calories_burnt'] = np.random.uniform(,)\n",
        "    state['calories_burnt'] += state['duration_mins']/(hiit_walk_mets * 3.5 * weight)/200\n",
        "    return state\n",
        "\n",
        "  def run(state):\n",
        "    state['duration_mins'] = np.random.randint(0,30)\n",
        "    state['heartrate'] = np.random.uniform(running_hiit_min, running_hiit_max)\n",
        "    state['sys_bp'] = np.random.uniform(run_sys_normal_min, run_sys_normal_max)\n",
        "    state['dia_bp'] += np.random.uniform(exc_dia_min,exc_dia_max)\n",
        "    state['spo2'] += np.random.uniform(running_spo2_min, running_spo2_min)\n",
        "    #state['vo2'] = 56.363 + (1.921 * pal_very_heavy_exc) - (0.381 * age) - (0.754 * bmi) + (10.987 * gender)\n",
        "    #state['calories_burnt'] = np.random.uniform(,)\n",
        "    state['calories_burnt'] += state['duration_mins']/(run_mets * 3.5 * weight)/200\n",
        "    return state\n",
        "\n",
        "  def cycle(state):\n",
        "    state['duration_mins'] = np.random.randint(0,30)\n",
        "    state['heartrate'] = np.random.uniform(cycling_min, cycling_max)\n",
        "    state['sys_bp'] = np.random.uniform(run_sys_normal_max, run_sys_normal_max)\n",
        "    state['dia_bp'] += np.random.uniform(exc_dia_min,exc_dia_max)\n",
        "    state['spo2'] += np.random.uniform(cycling_spo2_min, cycling_spo2_max)\n",
        "    #state['vo2'] = 56.363 + (1.921 * pal_very_heavy_exc) - (0.381 * age) - (0.754 * bmi) + (10.987 * gender)\n",
        "    #state['calories_burnt'] = np.random.uniform(,)\n",
        "    state['calories_burnt'] += state['duration_mins']/(cycle_mets * 3.5 * weight)/200\n",
        "    #state['calories_burnt'] = (21.76734 * speed_mph) - 179.2953\n",
        "    return state\n",
        "\n",
        "  def rest(state): #per minute\n",
        "    state['duration_mins'] = np.random.randint(5,10)\n",
        "    state['heartrate'] -= np.random.uniform(heartrate_drop_min, heartrate_drop_max)\n",
        "    state['sys_bp'] = initial_sys - np.random.uniform(sysbp_men_min, sysbp_men_max)\n",
        "    state['spo2'] += np.random.uniform(normal_spo2_min, normal_spo2_max)\n",
        "    #state['vo2'] = ((220 - age)/state['heartrate']) * 15\n",
        "    state['calories_burnt'] += np.random.uniform(0.06,0.15) * state['calories_burnt']\n",
        "    return state\n",
        "\n",
        "  #Risky conditions\n",
        "  def risky_conditions(state):\n",
        "    heart_rate = (state['heart_rate'] < safe_zone_min) or ((state['heart_rate'] > safe_zone_max))\n",
        "    sys_bp = (state['sys_bp'] > hyper1_sys_min) or (state['sys_bp'] < normal_sys_min)\n",
        "    dia_bp = (state['dia_bp'] > hyper1_dia_min) or (state['dia_bp'] < normal_dia_min)\n",
        "    if(gender == 1):\n",
        "      spo2 = ((initial_spo2 - state['spo2']) > 0.04) or (state['spo2'] <= risky_spo2_max)\n",
        "      #vo2 = (state['vo2'] >= lactate_threshold_min_men) or (state['vo2'] <= lactate_threshold_max_men) or (state['vo2'] < vo2_men_poor_max) \n",
        "    else:\n",
        "      spo2 = ((initial_spo2 - state['spo2']) > 0.03) or (state['spo2'] <= risky_spo2_max)\n",
        "      #vo2 = (state['vo2'] >= lactate_threshold_min_women) or (state['vo2'] <= lactate_threshold_max_women) or (state['vo2'] < vo2_women_poor_max)\n",
        "    return (heart_rate or sys_bp or dia_bp or spo2)\n",
        "\n",
        "  #Evaluating heart attack risk\n",
        "  def heart_attack_risk(state, heart_attack_proclivity=0.5):\n",
        "    # return heart_attack_proclivity * sigmoid(thalachh)\n",
        "    return 0.5\n",
        "\n",
        "  def heart_attack_occured(state, heart_attack_proclivity=0.5):\n",
        "    return np.random.uniform(0, 1) < sc.heart_attack_risk(state, heart_attack_proclivity)\n",
        "\n",
        "  def action_to_take(self, action):\n",
        "    if (action == 0):\n",
        "      state = sc.rest(state)\n",
        "      #self.rest()\n",
        "    elif (action == 1):\n",
        "      state = sc.walk(state)\n",
        "      #self.walk()\n",
        "    elif (action == 2):\n",
        "      state = sc.aerobic_walk(state)\n",
        "      #self.aerobic_walk()\n",
        "    elif (action == 3):\n",
        "      state = sc.hiit_walk(state)\n",
        "      #self.hiit_walk()\n",
        "    elif (action == 3):\n",
        "      state = sc.run(state)\n",
        "      #self.run()\n",
        "    elif (action == 4):\n",
        "      state = sc.cycle(state)\n",
        "      #self.cycle()\n",
        "    return state"
      ],
      "metadata": {
        "id": "ozIc_hgYuu3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actions = [sc.rest, sc.walk, sc.aerobic_walk, sc.hiit_walk, sc.run, sc.cycle, sc.weightlift]"
      ],
      "metadata": {
        "id": "OG2LCylvuyru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smartcoach_action_space = gym.spaces.Discrete(len(actions))"
      ],
      "metadata": {
        "id": "TIFE_1yvuzdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SmartCoach:\n",
        "  \n",
        "  def __init__(self, heart_attack_proclivity=0.5, max_steps=1000):\n",
        "    self.actions = actions\n",
        "    self.observations = observations\n",
        "    self.action_space = smartcoach_action_space\n",
        "    self.observation_space = make_smartcoach_obs_space()\n",
        "    self.heart_attack_proclivity = heart_attack_proclivity\n",
        "    self.log = ''\n",
        "    self.max_steps = max_steps\n",
        "        \n",
        "  def observation(self):\n",
        "    return np.array([self.state[o] for o in self.observations])\n",
        "        \n",
        "  def reset(self):\n",
        "    self.state = {\n",
        "                'heartrate' : np.random.uniform(general_thr_min, general_thr_max),\n",
        "                'sys_bp': np.random.uniform(normal_sys_min, normal_sys_max),\n",
        "                'dia_bp': np.random.uniform(normal_dia_min, normal_dia_max),\n",
        "                'spo2' : np.random.uniform(normal_spo2_min, normal_spo2_max),\n",
        "                # 'vo2' : np.random.uniform(normal_vo2_min, normal_vo2_min),\n",
        "                'calories_burnt' : 0,\n",
        "                'duration_mins' : 0 \n",
        "        }\n",
        "    self.steps_left = self.max_steps\n",
        "    return self.observation()\n",
        "        \n",
        "  def step(self, action):\n",
        "    if (self.state['duration_mins'] == 0):\n",
        "      old_score = 0\n",
        "      new_score = 0\n",
        "    else:\n",
        "      old_score = self.state['calories_burnt'] / self.state['duration_mins']\n",
        "        \n",
        "      # Do selected action\n",
        "      self.actions[action](self.state)\n",
        "      self.log += f'Chosen action: {self.actions[action].__name__}\\n'\n",
        "      if (self.state['duration_mins'] == 0):\n",
        "        new_score = old_score\n",
        "      else: \n",
        "        new_score = self.state['calories_burnt'] / self.state['duration_mins']\n",
        "    reward = new_score - old_score\n",
        "        \n",
        "    if sc.heart_attack_occured(self.state, self.heart_attack_proclivity):\n",
        "      self.log += f'HEART ATTACK\\n'\n",
        "      # We would like to avoid this\n",
        "      reward -= 100\n",
        "            \n",
        "    self.log += str(self.state) + '\\n'\n",
        "        \n",
        "    self.steps_left -= 1\n",
        "    done = (self.steps_left <= 0)\n",
        "        \n",
        "    return self.observation(), reward, done\n",
        "    \n",
        "  def close(self):\n",
        "    pass\n",
        "        \n",
        "  def render(self, mode=None):\n",
        "    print(self.log)\n",
        "    self.log = ''\n",
        "\n",
        "\n",
        "env = SmartCoach()"
      ],
      "metadata": {
        "id": "U7_ovPtsZC5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4482679f-8364-4b16-de96-007e1dd298da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/spaces/box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  -self.np_random.exponential(size=upp_bounded[upp_bounded].shape)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For stats\n",
        "ep_rewards = [-200]\n",
        "\n",
        "# For more repetitive results\n",
        "random.seed(1)\n",
        "np.random.seed(1)\n",
        "#tf.set_random_seed(1)"
      ],
      "metadata": {
        "id": "piKNjygru1hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQNAgent:\n",
        "  def __init__(self):\n",
        "    #main model that gets trained every step\n",
        "    self.model = self.create_model()\n",
        "\n",
        "    #target model - .predict against every step\n",
        "    self.target_model = self.create_model()\n",
        "    self.target_model.set_weights(self.model.get_weights())\n",
        "\n",
        "    self.replay_memory = deque(maxlen = REPLAY_MEMORY_SIZE)\n",
        "\n",
        "    self.target_update_counter = 0\n",
        "\n",
        "  def create_model(self):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_shape=(1,), activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate = 0.001))\n",
        "    return model\n",
        "\n",
        "  def update_replay_memory(self, transition):\n",
        "    self.replay_memory.append(transition)\n",
        "\n",
        "  def train(self, terminal_state, step):\n",
        "    if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\n",
        "      return\n",
        "\n",
        "    minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\n",
        "    \n",
        "    current_states = np.array([transition[0] for transition in minibatch])\n",
        "    current_qs_list = self.model.predict(current_states)\n",
        "\n",
        "    new_current_states = np.array([transition[3] for transition in minibatch])\n",
        "    future_qs_list = self.target_model.predict(new_current_states)\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for index, (current_state, action, reward, new_current_state, done) in enumerate(minibatch):\n",
        "      if not done:\n",
        "        max_future_q = np.max(future_qs_list[index])\n",
        "        new_q = reward + DISCOUNT * max_future_q\n",
        "      else:\n",
        "        new_q = reward\n",
        "\n",
        "      current_qs = current_qs_list[index]\n",
        "      current_qs[action] = new_q\n",
        "\n",
        "      X.append(current_state)\n",
        "      y.append(current_qs)\n",
        "\n",
        "    self.model.fit(np.array(X), np.array(y), batch_size = MINIBATCH_SIZE, verbose = 0, shuffle = False if terminal_state else None)\n",
        "\n",
        "    # updating to determine if we want to update target_model yet\n",
        "    if terminal_state:\n",
        "      self.target_update_counter += 1\n",
        "\n",
        "    #if self.target_update_counter > UPDATE_TAREGT_EVERY:\n",
        "    if self.target_update_counter > 5:\n",
        "      self.target_model.set_weights(self.model.get_weights())\n",
        "      self.target_update_counter = 0\n",
        "\n",
        "  # Queries main network for Q values given current observation space (environment state)\n",
        "  def get_qs(self,state):\n",
        "    return self.model.predict(np.array(state).reshape(-1, *state.shape)[0])\n",
        "\n",
        "agent = DQNAgent()"
      ],
      "metadata": {
        "id": "rj2DEMd7u7z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over episodes\n",
        "for episode in tqdm(range(1, EPISODES + 1), ascii=True, unit='episodes'):\n",
        "  # Restarting episode - reset episode reward and step number\n",
        "  episode_reward = 0\n",
        "  step = 1\n",
        "  #reward = 0\n",
        "  # Reset environment and get initial state\n",
        "  current_state = env.reset()\n",
        "\n",
        "  # Reset flag and start iterating until episode ends\n",
        "  done = False\n",
        "  while not done:\n",
        "    # This part stays mostly the same, the change is to query a model for Q values\n",
        "    if np.random.random() > epsilon:\n",
        "      # Get action from Q table\n",
        "      action = np.argmax(agent.get_qs(current_state))\n",
        "    else:\n",
        "      # Get random action\n",
        "      action = np.random.randint(0, 6)\n",
        "  \n",
        "      new_state, reward, done = env.step(action)\n",
        "  \n",
        "      # Transform new continous state to new discrete state and count reward\n",
        "      episode_reward += reward\n",
        "      #episode_reward += 1\n",
        "      \n",
        "      if SHOW_PREVIEW and not episode % AGGREGATE_STATS_EVERY:\n",
        "        env.render()\n",
        "     \n",
        "      # Every step we update replay memory and train main network\n",
        "      agent.update_replay_memory((current_state, action, reward, new_state, done))\n",
        "      agent.train(done, step)\n",
        "      current_state = new_state\n",
        "      step += 1\n",
        "\n",
        "    # Append episode reward to a list and log stats (every given number of episodes)\n",
        "    ep_rewards.append(episode_reward)\n",
        "    if not episode % AGGREGATE_STATS_EVERY or episode == 1:\n",
        "      average_reward = sum(ep_rewards[-AGGREGATE_STATS_EVERY:])/len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
        "      min_reward = min(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
        "      max_reward = max(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
        "  \n",
        "  # Decay epsilon\n",
        "  if epsilon > MIN_EPSILON:\n",
        "    epsilon *= EPSILON_DECAY\n",
        "    epsilon = max(MIN_EPSILON, epsilon)"
      ],
      "metadata": {
        "id": "rDyqJ8swvCTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customised A2C Model"
      ],
      "metadata": {
        "id": "1Or6hlas-jKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch  \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "vl3IGLfG-l2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "hidden_size = 256\n",
        "learning_rate = 3e-4\n",
        "\n",
        "# Constants\n",
        "GAMMA = 0.99\n",
        "num_steps = 300\n",
        "#max_episodes = 3000\n",
        "max_episodes = 1000"
      ],
      "metadata": {
        "id": "QPZVqMdi-u7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActorCritic(nn.Module):\n",
        "  def __init__(self, num_inputs, num_actions, hidden_size, learning_rate=3e-4):\n",
        "    super(ActorCritic, self).__init__()\n",
        "\n",
        "    self.num_actions = num_actions\n",
        "    self.critic_linear1 = nn.Linear(num_inputs, hidden_size)\n",
        "    self.critic_linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    self.actor_linear1 = nn.Linear(num_inputs, hidden_size)\n",
        "    self.actor_linear2 = nn.Linear(hidden_size, num_actions)\n",
        "    \n",
        "  def forward(self, state):\n",
        "    state = Variable(torch.from_numpy(state).float().unsqueeze(0))\n",
        "    value = F.relu(self.critic_linear1(state))\n",
        "    value = self.critic_linear2(value)\n",
        "        \n",
        "    policy_dist = F.relu(self.actor_linear1(state))\n",
        "    policy_dist = F.softmax(self.actor_linear2(policy_dist), dim=1)\n",
        "\n",
        "    return value, policy_dist"
      ],
      "metadata": {
        "id": "45AnuMbk-1V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def a2c(env):\n",
        "  num_inputs = 5\n",
        "  num_outputs = 6\n",
        "    \n",
        "  actor_critic = ActorCritic(num_inputs, num_outputs, hidden_size)\n",
        "  ac_optimizer = optim.Adam(actor_critic.parameters(), lr=learning_rate)\n",
        "\n",
        "  all_lengths = []\n",
        "  average_lengths = []\n",
        "  all_rewards = []\n",
        "  entropy_term = 0\n",
        "\n",
        "  for episode in range(max_episodes):\n",
        "    log_probs = []\n",
        "    values = []\n",
        "    rewards = []\n",
        "\n",
        "    state = env.reset()\n",
        "    for steps in range(num_steps):\n",
        "      value, policy_dist = actor_critic.forward(state)\n",
        "      value = value.detach().numpy()[0,0]\n",
        "      dist = policy_dist.detach().numpy() \n",
        "\n",
        "      action = np.random.choice(num_outputs, p=np.squeeze(dist))\n",
        "      log_prob = torch.log(policy_dist.squeeze(0)[action])\n",
        "      entropy = -np.sum(np.mean(dist) * np.log(dist))\n",
        "      new_state, reward, done = env.step(action)\n",
        "\n",
        "      rewards.append(reward)\n",
        "      values.append(value)\n",
        "      log_probs.append(log_prob)\n",
        "      entropy_term += entropy\n",
        "      state = new_state\n",
        "            \n",
        "      if done or steps == num_steps-1:\n",
        "        Qval, _ = actor_critic.forward(new_state)\n",
        "        Qval = Qval.detach().numpy()[0,0]\n",
        "        all_rewards.append(np.sum(rewards))\n",
        "        all_lengths.append(steps)\n",
        "        average_lengths.append(np.mean(all_lengths[-10:]))\n",
        "        if episode % 10 == 0:                    \n",
        "          sys.stdout.write(\"episode: {}, reward: {}, total length: {}, average length: {} \\n\".format(episode, np.sum(rewards), steps, average_lengths[-1]))\n",
        "        break\n",
        "        \n",
        "  # compute Q values\n",
        "  Qvals = np.zeros_like(values)\n",
        "  for t in reversed(range(len(rewards))):\n",
        "    Qval = rewards[t] + GAMMA * Qval\n",
        "    Qvals[t] = Qval\n",
        "  \n",
        "  #update actor critic\n",
        "  values = torch.FloatTensor(values)\n",
        "  Qvals = torch.FloatTensor(Qvals)\n",
        "  log_probs = torch.stack(log_probs)\n",
        "        \n",
        "  advantage = Qvals - values\n",
        "  actor_loss = (-log_probs * advantage).mean()\n",
        "  critic_loss = 0.5 * advantage.pow(2).mean()\n",
        "  ac_loss = actor_loss + critic_loss + 0.001 * entropy_term\n",
        "\n",
        "  ac_optimizer.zero_grad()\n",
        "  ac_loss.backward()\n",
        "  ac_optimizer.step()\n",
        "\n",
        "        \n",
        "    \n",
        "  # Plot results\n",
        "  smoothed_rewards = pd.Series.rolling(pd.Series(all_rewards), 10).mean()\n",
        "  smoothed_rewards = [elem for elem in smoothed_rewards]\n",
        "  plt.plot(all_rewards)\n",
        "  plt.plot(smoothed_rewards)\n",
        "  plt.plot()\n",
        "  plt.xlabel('Episode')\n",
        "  plt.ylabel('Reward')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(all_lengths)\n",
        "  plt.plot(average_lengths)\n",
        "  plt.xlabel('Episode')\n",
        "  plt.ylabel('Episode length')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "k_JH69PM-5bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = a2c(env)"
      ],
      "metadata": {
        "id": "tDZ5SjdA-9pE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc7b099e-0ab7-43cc-b7fd-62a57882120c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 0, reward: -14400, total length: 299, average length: 299.0 \n",
            "episode: 10, reward: -14900, total length: 299, average length: 299.0 \n",
            "episode: 20, reward: -15600, total length: 299, average length: 299.0 \n",
            "episode: 30, reward: -14000, total length: 299, average length: 299.0 \n",
            "episode: 40, reward: -14300, total length: 299, average length: 299.0 \n",
            "episode: 50, reward: -12100, total length: 299, average length: 299.0 \n",
            "episode: 60, reward: -15000, total length: 299, average length: 299.0 \n",
            "episode: 70, reward: -14900, total length: 299, average length: 299.0 \n",
            "episode: 80, reward: -16700, total length: 299, average length: 299.0 \n",
            "episode: 90, reward: -13400, total length: 299, average length: 299.0 \n",
            "episode: 100, reward: -14800, total length: 299, average length: 299.0 \n",
            "episode: 110, reward: -13600, total length: 299, average length: 299.0 \n",
            "episode: 120, reward: -15400, total length: 299, average length: 299.0 \n",
            "episode: 130, reward: -15700, total length: 299, average length: 299.0 \n",
            "episode: 140, reward: -15100, total length: 299, average length: 299.0 \n",
            "episode: 150, reward: -17400, total length: 299, average length: 299.0 \n",
            "episode: 160, reward: -14700, total length: 299, average length: 299.0 \n",
            "episode: 170, reward: -14200, total length: 299, average length: 299.0 \n",
            "episode: 180, reward: -16000, total length: 299, average length: 299.0 \n",
            "episode: 190, reward: -13400, total length: 299, average length: 299.0 \n",
            "episode: 200, reward: -13900, total length: 299, average length: 299.0 \n",
            "episode: 210, reward: -15900, total length: 299, average length: 299.0 \n",
            "episode: 220, reward: -16800, total length: 299, average length: 299.0 \n",
            "episode: 230, reward: -15500, total length: 299, average length: 299.0 \n",
            "episode: 240, reward: -15100, total length: 299, average length: 299.0 \n",
            "episode: 250, reward: -14300, total length: 299, average length: 299.0 \n",
            "episode: 260, reward: -14600, total length: 299, average length: 299.0 \n",
            "episode: 270, reward: -15600, total length: 299, average length: 299.0 \n",
            "episode: 280, reward: -13900, total length: 299, average length: 299.0 \n",
            "episode: 290, reward: -13700, total length: 299, average length: 299.0 \n",
            "episode: 300, reward: -14200, total length: 299, average length: 299.0 \n",
            "episode: 310, reward: -17100, total length: 299, average length: 299.0 \n",
            "episode: 320, reward: -15100, total length: 299, average length: 299.0 \n",
            "episode: 330, reward: -14100, total length: 299, average length: 299.0 \n",
            "episode: 340, reward: -15600, total length: 299, average length: 299.0 \n",
            "episode: 350, reward: -15600, total length: 299, average length: 299.0 \n",
            "episode: 360, reward: -15300, total length: 299, average length: 299.0 \n",
            "episode: 370, reward: -15200, total length: 299, average length: 299.0 \n",
            "episode: 380, reward: -16200, total length: 299, average length: 299.0 \n",
            "episode: 390, reward: -14500, total length: 299, average length: 299.0 \n",
            "episode: 400, reward: -14400, total length: 299, average length: 299.0 \n",
            "episode: 410, reward: -15900, total length: 299, average length: 299.0 \n",
            "episode: 420, reward: -14200, total length: 299, average length: 299.0 \n",
            "episode: 430, reward: -15900, total length: 299, average length: 299.0 \n",
            "episode: 440, reward: -14100, total length: 299, average length: 299.0 \n",
            "episode: 450, reward: -14400, total length: 299, average length: 299.0 \n",
            "episode: 460, reward: -16200, total length: 299, average length: 299.0 \n",
            "episode: 470, reward: -15900, total length: 299, average length: 299.0 \n",
            "episode: 480, reward: -14300, total length: 299, average length: 299.0 \n",
            "episode: 490, reward: -15000, total length: 299, average length: 299.0 \n",
            "episode: 500, reward: -15700, total length: 299, average length: 299.0 \n",
            "episode: 510, reward: -15600, total length: 299, average length: 299.0 \n",
            "episode: 520, reward: -15600, total length: 299, average length: 299.0 \n",
            "episode: 530, reward: -15400, total length: 299, average length: 299.0 \n",
            "episode: 540, reward: -15400, total length: 299, average length: 299.0 \n",
            "episode: 550, reward: -14700, total length: 299, average length: 299.0 \n",
            "episode: 560, reward: -15100, total length: 299, average length: 299.0 \n",
            "episode: 570, reward: -14500, total length: 299, average length: 299.0 \n",
            "episode: 580, reward: -16500, total length: 299, average length: 299.0 \n",
            "episode: 590, reward: -14600, total length: 299, average length: 299.0 \n",
            "episode: 600, reward: -15400, total length: 299, average length: 299.0 \n",
            "episode: 610, reward: -13700, total length: 299, average length: 299.0 \n",
            "episode: 620, reward: -18000, total length: 299, average length: 299.0 \n",
            "episode: 630, reward: -15800, total length: 299, average length: 299.0 \n",
            "episode: 640, reward: -14900, total length: 299, average length: 299.0 \n",
            "episode: 650, reward: -16400, total length: 299, average length: 299.0 \n",
            "episode: 660, reward: -14600, total length: 299, average length: 299.0 \n",
            "episode: 670, reward: -15500, total length: 299, average length: 299.0 \n",
            "episode: 680, reward: -15900, total length: 299, average length: 299.0 \n",
            "episode: 690, reward: -12800, total length: 299, average length: 299.0 \n",
            "episode: 700, reward: -14900, total length: 299, average length: 299.0 \n",
            "episode: 710, reward: -14600, total length: 299, average length: 299.0 \n",
            "episode: 720, reward: -15800, total length: 299, average length: 299.0 \n",
            "episode: 730, reward: -14400, total length: 299, average length: 299.0 \n",
            "episode: 740, reward: -14800, total length: 299, average length: 299.0 \n",
            "episode: 750, reward: -16700, total length: 299, average length: 299.0 \n",
            "episode: 760, reward: -17000, total length: 299, average length: 299.0 \n",
            "episode: 770, reward: -16100, total length: 299, average length: 299.0 \n",
            "episode: 780, reward: -15700, total length: 299, average length: 299.0 \n",
            "episode: 790, reward: -14500, total length: 299, average length: 299.0 \n",
            "episode: 800, reward: -14200, total length: 299, average length: 299.0 \n",
            "episode: 810, reward: -14700, total length: 299, average length: 299.0 \n",
            "episode: 820, reward: -14500, total length: 299, average length: 299.0 \n",
            "episode: 830, reward: -14700, total length: 299, average length: 299.0 \n",
            "episode: 840, reward: -16400, total length: 299, average length: 299.0 \n",
            "episode: 850, reward: -13300, total length: 299, average length: 299.0 \n",
            "episode: 860, reward: -15100, total length: 299, average length: 299.0 \n",
            "episode: 870, reward: -14800, total length: 299, average length: 299.0 \n",
            "episode: 880, reward: -13500, total length: 299, average length: 299.0 \n",
            "episode: 890, reward: -16500, total length: 299, average length: 299.0 \n",
            "episode: 900, reward: -15900, total length: 299, average length: 299.0 \n",
            "episode: 910, reward: -15500, total length: 299, average length: 299.0 \n",
            "episode: 920, reward: -14900, total length: 299, average length: 299.0 \n",
            "episode: 930, reward: -14700, total length: 299, average length: 299.0 \n",
            "episode: 940, reward: -15300, total length: 299, average length: 299.0 \n",
            "episode: 950, reward: -14500, total length: 299, average length: 299.0 \n",
            "episode: 960, reward: -16000, total length: 299, average length: 299.0 \n",
            "episode: 970, reward: -14200, total length: 299, average length: 299.0 \n",
            "episode: 980, reward: -15300, total length: 299, average length: 299.0 \n",
            "episode: 990, reward: -16400, total length: 299, average length: 299.0 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEGCAYAAABcolNbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAACEhklEQVR4nO2dd9wUxf3HP9+rT+N5HjoICIgoolhRsfefKDF2E43dWKLGGlvUxBITYyyxxN5L1Gjs2LFHRUFBaSogUqSXpz/Ptfn9sTO7s7uze3v33D13PMz79YLnbrbN3s7Od75lvkOMMWg0Go1GUyxCpa6ARqPRaLo3WtBoNBqNpqhoQaPRaDSaoqIFjUaj0WiKihY0Go1GoykqkVJXoNzo06cPGzZsWKmrodFoNOsVU6dOXcUY66vapgWNg2HDhmHKlCmlroZGo9GsVxDRT17btOlMo9FoNEVFCxqNRqPRFJWSCBoiOpqIZhJRhojGSuUHENFUIvqW/91X2rYDL59LRHcQEfHyXkT0DhH9wP/25OXE95tLRN8Q0fZdf6cajUajKZVGMwPAEQA+cpSvAnAIY2wMgJMAPCFtuwfA6QBG8n/jefnlACYxxkYCmMS/A8BB0r5n8OM1Go1G08WURNAwxmYzxr5TlH/NGPuZf50JoJKI4kQ0EEAtY+xzZiRnexzAYXy/QwE8xj8/5ih/nBl8DqCen0ej0Wg0XUg5+2iOBPAVY6wDwCAAi6Vti3kZAPRnjC3ln5cB6M8/DwKwyOMYG0R0BhFNIaIpK1euLFT9NRqNRoMihjcT0bsABig2XckYeznLsVsC+DuA/8vlmowxRkQ5p6NmjN0P4H4AGDt2rE5nrdFoNAWkaIKGMbZ/PscR0WAALwI4kTE2jxcvATBY2m0wLwOA5UQ0kDG2lJvGVkjHDPE4pqzIZBie/2oxDt9uEKLhclYyNRqNJnfKqlcjonoAEwFczhj7nyjnprFGIhrHo81OBCC0oldgBA6A/5XLT+TRZ+MANEgmtrLi+a8W49Lnv8EDH88vdVU0Go2m4JQqvPlwIloMYBcAE4noLb7pXACbAvgTEU3j//rxbWcDeBDAXADzALzBy28EcAAR/QBgf/4dAF4HMJ/v/wA/vixZ25Kw/dVoNJruRElS0DDGXoRhHnOW/wXAXzyOmQJgK0X5agD7KcoZgHM6XdkuQDiF+NQgjUaj6VaUlelsQ0Wspq3ljEaj6Y5oQVMGZLikIWhJo9Fouh9a0JQRWqPRaDTdES1oygDGNZqQFjQajaYbogVNGZARPhptOtNoNN0QLWjKCG0602g03REtaMoAppPeaDSabowWNGUA4zNp9DwajUbTHdGCpgywfDQajUbT/dCCphwQ82i0pNFoNN0QLWjKADMFjdZpNBpNN0QLmjJABAPoeTQajaY7ogVNGZDRpjONRtON0YKmDNDZm735csEa3PL2d6WuhsaHH5Y34U8vz0Amo+P0NWq0oCkDdPZmb46+9zPc+d7cUldD48Opj32Jxz/7CYvWtpa6KpoyRQuaMoDp7M2aboBuvxovtKApAyzTWUmroVmPWdeawNcL15bk2jqzhSYbWtCUAZZGo9Hkx3EPTMbhd39a0jrogZLGCy1oygArvFm/qZr8mLW0sWTX1hqNJhta0JQBGR0MoNFoujFa0JQBDHpIWA6sbOrAsMsn4qWvl5S6KnnD1nP1YsaSBgy7fCKm/lQaf1M5MOzyibjmlZmlrkZB0YKmDLDCm7VKU0rmrWwGAPz7i4Ulrkn+lFLOFKL5fvj9SgDAu7OXd/5k6zGPfrqg1FUoKFrQlBFazJQW8/dfj5WCUlR9fdeiNMVHC5oygAVIQfPurOX479TFXVSjDROhURbKlPngx/Mx9ac1BTlXUErZ6Xd3jXzaonW478N5pa7GeklJBA0RHU1EM4koQ0RjpfKdiGga/zediA6Xto0nou+IaC4RXS6VDyeiybz8WSKK8fI4/z6Xbx/WpTeZA1b2Zm9++/gUXPzc9K6ojqZA/GXibBx5z2ddes2SaDQluGYpOOxf/8Pf3phT6mqsl5RKo5kB4AgAHynKxzLGtgUwHsB9RBQhojCAfwE4CMBoAMcS0Wh+zN8B3MYY2xTAWgCn8fLTAKzl5bfx/coSM7xZp28uC9ZnS1BJfTSlu7SmzCmJoGGMzWaMuTIlMsZaGWMp/rUC1mBpJwBzGWPzGWMJAM8AOJQMXX1fAM/z/R4DcBj/fCj/Dr59PypT3T5T5hM2MxlW9lFALR0pzPrZPZdkeWM7Fq0JloNL1ToYY5iyYE3OJqlSmbBKEcEY5FbnrWzGmpZE8SuzgbBwdSuWN7aXuhqBKTsfDRHtTEQzAXwL4CwueAYBWCTttpiX9QawThJOohzyMXx7A99fdc0ziGgKEU1ZuXJloW8pK+Z7Wp5yEA98PB9H3vMpPp27qtRV8eSMJ6bg4Ds+RjKdsZXv/NdJ2OOm93M6l9xvvjL9Zxx172d4MceQ51SJMhmXa9TZfrd8iP1v/bDrKtPN2fMf72Pnv04qdTUCUzRBQ0TvEtEMxb9D/Y5jjE1mjG0JYEcAVxBRRbHqKF3zfsbYWMbY2L59+xb7corrG3/LU8wA3y1vAgD83FC6EVQ2DeHLHw2NK9OJnlb8/vK1FqwytKEfV7XkdK5EKpN9p25CUC1KazQbLpFinZgxtn8nj59NRM0AtgKwBMAQafNgXrYaQD0RRbjWIsohHbOYiCIA6vj+ZYjxouoUNN4w5j9iLoTJSHV+UZar/HJqVl1FaX00uv1q1JSV6YxHkEX456EARgFYAOBLACP59hiAXwN4hRlDz/cBHMVPcRKAl/nnV/h38O3vsTIN+M/wPknu6Eb88XXc+s73pamQB6X8+bJd2dIKC9vZmVpOjoKsVBpNufpo1ndWrEf+kHKkVOHNhxPRYgC7AJhIRG/xTbsDmE5E0wC8COBsxtgqrq2cC+AtALMB/IcxJnI0XAbgIiKaC8MH8xAvfwhAb15+EQAzJLrcEJ2D3EWmMwx3TPqhNBVyIDrv9aE/6VxHW7j77CiVoCnBQ1of2kVnmb64odRVWK8pmunMD8bYizAEibP8CQBPeBzzOoDXFeXzYUSlOcvbARzd6cp2AeW+wmY51MvQprJXpDMdbb5mMhXCdBYNd+2PV8pOvzvn7CuDV2C9pqxMZxsq1oTN4M15ybo2/Ov9uRtM+o9S3WW+widhCpqufcVK0R6Kccly69hD63FPOXtpI574bEFJ61ASjUZjJ59IqdMfm4JZSxsxYcxADOtTXYRaKSihTMv2ExWyavK5rLQ0uZFMGUdEungSbkk1mgJevNyGT2U6BS8QB93+MQDghF2GlawO67Gc7kYw8Sf469WaMKYOdSacNyjl8Ipl+23ESL5YP0fuGk0aQCk0mi69nLhqKS7apZTDO7A+owVNGZDPa1rqEVZHKm2m1S8nOuMnMM1OUm9tms5yPK8IBuhqQQMGzF3RXJKotyC/0Iqmdqxq7jC/tyXSWBBgjtLKpg6sbOrIul+xyGXqQVsi7Tvvas6yRpuJc9GaVjS2Jz33X9OSWK+yAKjQgqYM6MxovFRjyStfnIH9bvkQa7toEl7Q36YzI/qMqVlamH6znOfRcNNZFwcDrGzuwP63fog/vTyjy66Zy2++0w2TMPYv75rfz3xyKva++YOsx+14w7vY8YZ3s+5XLHIRNOf8+yvsc/MHSCnmUk39aS3G//NjPPTJj2bZHje9j0Pu/MTzfNtf/856lQVAhRY0ZYR4X4M4dEutyn82z5j72tyRyrJn19IZwav62Sk/OWNqFF2t0TS0GSPjyT927fIEQH6BCB/xhc6cx5a6fTuR5Uy2+xT3pMpCJPLufeMIl/5pdWugc6+vaEFTRigsN2WFbD4qZChwoGt3QTCAyt+lSksTBCFoujwYoAQJWgvz2xfgJEUkl9/TT/nJphiV67vfWbSgKSBH3vMprn2182t9y21tdbPbLp1MZzA/gF175s/G+utBsxd7IQuVu977AXv/433TlNBVcyf+8Nx0nPLIF57bLSGdf30ykglz++vfweOfLXB1DOP/+RFufsuVeNyFmEcT6WKNRnTYRMak363+/Bb+M2WR/0EFwuunD/JMPpm7CsOvmGhqZGXX39o0mmCH+L0bXlvK7r4LhBY0BWTqT2vxyP8W5H28aJjyyHraonWu/ZraLXOVX6P/z5dGB9PZ9dfl+T03v/09Fqxu7XKNZuK3S/H+d9kza3eqOlL035qWBP70sjVoEPc5Z1kT7np/btZTWaazrtVozCUniNCSSKG5I4XrXp1V1GtmEyRB2si/3psLxozBUTki+2iCtjG/+/b6zbTpTFN0VKYz1WJoQUOaxWg6XQS7hJUDrLwoSDCAdI580+90pEtjOpPXNsrwGyr1enpB2mtXhOl3Bpug6UyG8PV4Pk5n0IKmi/n35IVYuFptyjKDAaRuLaxomEHa+XtzluPrhWsBAPd+OL9TL8cr03+21Q+wXpggHcQj//txvUhKKO5FFsx5Z29Olch0xgOdQkSm4AwHlDRLG9rymkGe7acJMs5xtqN8uuMZSxrw+rdL8zgyO7ZggGz7Ivu70dCWxH0fznO9l8UUt6XUlnRmgC6kI5XGH1/8FgPrKvDZFfuZ5c7HL7cHVSdht/2qG8+pj04xP69q7sBXC9dih6G98qk22pJpV5nlJPc/dsGqFlz76iy8Ov1nvHD2bnldPyc68S5ZUX+qbTkGA3CNJtblPhphOrMEZtDQ3FMe+RJzljXhwC0HoF9t7stAebWFIIORQnSBv+AhwgtunFCAs9nJR/Apoxj5349/WIWPf1iFUQNrsx5TKLIttVFMtEbThYgXf22rx9wTxXwaZSchbQ/aMBOpwrZgq1r+5xUrTa5r856QVkg6E5xgajS2CZvcdJbjac2osxL5aOTPKvOrinWtxjNK53izWSMCA2k0OV2yy7EN7QIHA2Qn6ZhYW8zgmlL+xFrQdCGi03Waw5z+DpvpTOmj8b7GiqZ2tKs0kAL3d3IHvKyhHR0p9zXl6y7LY3XOhtbchZNXJ9CWSGNFk38dhGkhI5vOPPb9eV2b7+JmYltXL2a3gs+eN0xn6vZWLLw6yUAajelbcvvEMmUgheRbyCoM+M8t33dLR8qWEUHF4rWdiw7NRilNZ1rQdCHptHqE6Xz88nulsrz4vbg73TAJJz3sHQbcGexOclEXYNzfJuH8p6cpjxH7tSbSSgHoxzbXvZ1zHb049oHPsdMN/rOrxf2ZmgB5C+hdb3wPN705x/NcwnTW1S/3pc9/A8Cot2hHuQYD5FrlbPcYTNAYf1W/970fzcutQkVAvod8slT84s5PbBkRVOz+9/exeG1bPtULRCnltRY0XUgy4z/KVc0FUUWpZPPQdMWscFEtYQ58c+Yyj/2s+nfF8sZe75IqTNxJhtn/UpZIoy8XrPU+Fz9Jqd5tIinqLKCkyTcLgp9vK+j5/IIBJs/v+iwHTvIaL0jHiNxn2ZTLFY3Fy+dWyvWCtKDpQlJco/GKAjJNN1l8NF4jSD8TQ74Da/mctswAvCvIFjot174rQjsLMWFT3BPB3wncpybmcy77364mRGTeR9Cos84+Ha9bZQHGF36/U6nDs4H82lU+HXsxX5FSRpBrQdOFHHXPpwB8NBrXB+Clr5fgF3d+bN/Po8EksmgM6QzDvrd8gInfBA8B9XIMi1tIcS3N6wWRy527HHz7x/jv1MWB6wIAn85d5bv97g/8zSxnPD7Fc5vTdJYtpLVXtVvQTP1pDXa64V1rhnsOb/d7c5Zjj5vew7/en4sTHpoMADjt0S9xZx5LehOsZ1dIP9G9H84z62bCb/H75U3Y/vp3XKHsufhoVAQVlEF4/dul2PfmD3KeWybvvcP17ygzdghEbX9x5yfmpGlrm7/Z3Pmsflje5FuvsX95B0sbimduKxRa0HQhP3OHeLb3Rh4JPfrpAsxY0mjf7vGOdCT9BU1rIoX5K1tw6fPTs1eWk+2FzK7ReGtvs5Y24uLngtcFAG708YsAsGXFVfH2LO8sCZZGaTmm5aAHZ2cYj4Rd57j1ne+xoqnDnMOUyyjy6pdmYtGaNvzjre/w8Q+GQJ00ZwVueef74CcREOU9YdOv07/xjTlm3Zw8/MmPWNOSwLuzV9jKc/HRqBObFk7QXPLcdMxf1WKu5xQUuV4tiTT+x5PK+rF4bRsu/e83tjLnrbhMho7tj366wPcaq5oTgQeOWqPZwPA2nRl/sw22ZEEkNx4R+aWajW7TLHJ4cVMZ9bXEZ5EOPwi2SKLSBxK5EHUyFUOS/RbMJVR9c1mx7Ps4KWQGhxBJUY6BfTT5hXI7fTTOy+UyYVP1GxTSdGbl6MsNp0AoVJ0KkbU6aJCN9tF0M75auNZMo68im+ksl9xRcuMRi23FIu7Hyhjw1sxgOc/mrWzG29y5/6GUX+zz+dY9ievK/gwVXunVnR1KayKFxz9bkPXei2muF/fETJOTfWKq04yonpBnnxWeCeCfmL+yGW/NXOY78n/x68U5LX5FyH3CZmfxMtUFMR+q5jAJCmk6M5cXUjyX5Y3tePFrtSnXWaspPoEgvtmbned1nDifR6WaUK1CR511M464+1Mc+8DnnttDHr+6uQBalvN7+U2yrer4B26mytaW97vlQ5zxxFQAxiJOgtckFV1UIRWkJ1XgFDTXvzYbf3p5Jj78PnvizGJhajTynA5pBBxkpG8lRrV/92PfWz7EmU9M9RU0Fz47Hcc/ONlzuxOS5tEUOwjDZXLMQ6MRu6gCWgpZf2vOmvs6Jz70BS58drpytUunsMxm0gqK+3Ydc+wC3Hp7FpO5QM+j2cDINoEum01bbjAq05lKo7ER8L31a5hiSyqL6cyufVk4heXP6wyHZtZ7993aOcT9mlqaU6Nxmc68MTWaHCqczXS2KIcJfXbTWbBjOtufZzJqwZaLj0Y1iCqkRuZnHhRO9bSiTReqj87mo8lHeQtuOisdWtB0AWtaErZOxOvFWS2WRc7SIrz6I9N0VqD8Wtmi2ADj3vzw8ic5X2ah/ldGI2hqT3pmGigmToc0wZ5qJ5cMw+auPoc0tCZty/1mE0q5+MMIVjBAtoFNIpWxjeJVt7muNeEpCE1txNNHE0TQCFOjwnQWoPMt1hytRCqDn1a35O3fyGb2c2YLyOcqQU1npQwG0Ek1i0xLRwrbX/8OTtltmFnm9d7f88E8HLTVAPTPktDQ68UNml8r6KCpLeHdgEXH4Iyqce8nf7E+Okeu4lpVsTDGXPM2th5cF7CWhcPSQqyRuZkShbn9LX4vrrmImldalgzDNte9jSO2G+Q6xoucggVI1sz8n/jxD03GFz+uwZBelcrtLR0pbHvdOzh512G+57EyKjh9NNmr6zRbygTRaM6VTLx++E1KVWUkv/LFb/Hc1MW48uAtAp0fsEdaugWN/fu1jrWC8jFvZYs2tU6e86kLRkk0GiI6mohmElGGiMYqtm9MRM1E9AepbDwRfUdEc4nocql8OBFN5uXPElGMl8f597l8+7AuuTkHYqT178kLzTJn45Pb1pxlTVk7HC+3iNeL7iRbxyM2t/gJmoDntKXukI5y+nbEqEz8Ns411c3reNao81hRZ1aAg3xbuSSbzGY6E8UvTltiHVPgqLOgEza/cGSScArHFh4K/JpHGK0zWjKbeUiFFXXm3hbERxM00MUyhap8QeB1sLb9j8/b8kyEm4Vc88w5m4DX9ACZoNrWhhh1NgPAEQA+8th+K4A3xBciCgP4F4CDAIwGcCwRjeab/w7gNsbYpgDWAjiNl58GYC0vv43vVzI6pCytfoKAkH0E6Jl3qUDtqCpqzA9p7chtroEKW/WkL05hKTSaUqr3fk5txlQdpndlrUXUPMxNQuPx0fI6A4HM8wXt7IJ0an5Y83acPprsxzKf36ugQWem1uK9T0qxMd9n45xqkO1R5DPYCFq1DW4eDWNsNmNMufA6ER0G4EcAM6XinQDMZYzNZ4wlADwD4FAyWs2+AJ7n+z0G4DD++VD+HXz7flSC5e1U7WbOsiYc/+Bkj1EVZR0BypsXrmnB+H9+hNXNHYEdzw1tSRx0+8dYwPMvAcCTn/+E/W/9EIff/T8zN5afRhNUqAUNBhAaTS6jrte/XYrTHv0y8P6C1c0dOOj2j7Fojd257h6ZW83l2SmLzDT6fjg7zGwajUzQ5/fN4nU49K5PfE2b8no0qlY/d0UzDrr94xwzZFsVPOqeTzHxm6UY/8+PzGf3HZ/FHiLCy9OW4CweuejVnmUntnMezd0fzMOwyyfiX+/P9WwRf3huOp78/CdXeUNbEgff/jHmrmh2bRM/xZlPuDNEiG2yRiM+qQIEvJB/71yXifBrA1e88A0eU0S7+fUXciaNUq5iWlbBAERUA+AyANc6Ng0CIOdyWMzLegNYxxhLOcptx/DtDXx/1XXPIKIpRDRl5crChtd6jWg/mbvKHDk5O4JcNJr7PpqPOcua8Pq3S81OOkjTnr20EfdI6VquemkG5q5oxtcL16Gp3fg5Uz4OVpfpLMCetnk0jhc3ZWY7zlp1k7Of+gqT5qzIvqODV6b/jNlLG/Hgx/Nt5a5cZ2Svz0eO0Gt/Hw3fx2O76tigo9lrX52F6YsbMONntXkRyJ7r7M73fsDspY147zvL5OS1mqjspxJM+Wktzvn3V5izzJ0iJUTA+c9MMxOter0DM3+2Ml54zaP5x1vK8SgA4Pmpi3HVSzNc5e/NWY5ZSxtx13vu1D1i8PDVwnWe21STlPO1ajp/+2zvpmsCp3TA018swp9fmQknfu3wvGemWftluXYxKZqgIaJ3iWiG4t+hPoddA8MM5h6KFBHG2P2MsbGMsbF9+/bN9xzK8lzMBkAwIaEamWSYf4NTaQqdCSUO6rQMqtGIb1lHXTkkGfVCvPxedTAvBUfUnGO7qq6iemYwgJfpTPHrBjXPBPHFyRqNStCojhRl2dKiZMMd3uxdR4HZoSt2znUgLsZHqt8nyL2kFU7QfLWBXCebBusv/NutjGy665ZRZ4yx/fM4bGcARxHRTQDqAWSIqB3AVABDpP0GA1gCYDWAeiKKcK1FlIP/HQJgMRFFANTx/YuC10PMlqZkxpIGzFhijUyNdUS8j5k8fzUWrnHPp2Asd1dftv19s0HncQ2bP8LxMpsmp4DnlZFHxjKfeOTkEh1QY1sKr0z/Gb/cZiO0J9N44Sv7rHAicqTdUdeuoS2JT35YhQlbD3R1mI1tSbw6/Wf0qYljQF0Fhvep5udynydoR5DxESDmPswKxw5qMV6w2mhXzmrk+myChjfLgkA0NZV/JNeW7beyqN8vIbaJOjDGsIxnY8hlYrJ8jUgolFPSy1zmHHl9B4CFq1uxaG2rWX/A+3f8cVULlja0YdcRfQLXM1fKKryZMbaH+ExE1wBoZozdxQXFSCIaDkOA/BrAcYwxRkTvAzgKht/mJAAv81O8wr9/xre/x4o4NdazgWTRMsQ657Zyn2N+db864wCD/8he5ejN9mv4azSO83u8wV5RZ06rnKUB+NdJheo3BIywXRWig3tl+s94ZfrP2Kx/DZ6evNC1voyh0Xgj6nrBM1/j/e9WYqtBe7u2LVjdit8//bVZXoj17L1WapXJZOSRvfe5ggi8XF8bVzCARx8t7yUGHqpL9VZkyfZDTiHkumYAmSsmIU/81oqyy3eaTigEHCK1z2xC329dHoFKFDvZ8x/vBzkQALDPzR8AKEzb9KJU4c2HE9FiALsAmEhEb/ntz7WVcwG8BWA2gP8wxoSx8jIAFxHRXBg+mId4+UMAevPyiwBcjiLiNfj3U4VVLxVRfqN6JpvOFK1TNZrJNlL0G13lNUlM+uwcIVr7FV+/d3ZAyRTDcsWCU+R00niwiK+KmEjJky+zmCU7cZvmxEift1fWaNQmJL8Oz165XP0Tznp5tTO5CiKNimquUIRPQB5Ur57n48TXdOaj0zjNnmulycj5hp5HQiGsag4eGu1sN6qrukxnAatWQstZaTQaxtiLAF7Mss81ju+vA3hdsd98GFFpzvJ2AEd3qqI54NWxBMnwK0PIHnVm39+6vq/gyMNUI4dkOwka+uzlo2npsAsqUfdsKW0Efmk32pNp3+wITpNKJEzKTjvkEPqukT7/KzqhRA6z/IOYg7w6N68wYpn2VMacw5VrqKXzstn8TU6cnblXO5LrLwYuKj9Vrtf3NZ0F+DGa2lNIpjO2eucb3pxrMEAQC53X88mGaA/pDEMynUFF1L7MBWOsaHnxyirqrDuSq4M+2zGBrqU4XtVnZXtxT3nEO3S4Oi7GKAw3Re7DruSO/jG2SqYz/vHbxQ045r7PHHUx/v7xxW9960QwZqqPuvpNz31GXf0mbn7bO1rJaXKKhEj5gjkVGs9Z/nynCXd8IkUpdV6j+cvE2cpyc36Mj01s+qJ1uOg/0wH4d66BTGeOv9lwXu+Iuz8NeKR/MEDQ6/uaznyvZWz9zYOTMfLKN2y/fy4ajdyWnPNosp0lkI8mT93krCd5otynvlK+P34Dy86iBU2B8Gogfg3H03SWh6SRTWdKdTuQZTc4I/rWAADiSOKYyId4LHKDZ72cdZi2eJ1nXeatbHFtcyLCr/141rGyoYyzg46EQ55mFs/JsdJ3uQ8K6msK8ts/++VCZbmZvFKxLYw0/hm9C1vSArNMKUR96+YwneVoNgo6Klbtpnpf0plgv6lz/2wmw1yi61RBCkFQaQ1+uDMDuPEaCGRDLKAows6d0xf85mV1Fi1oCoTnxLzcrFm+5Srk/Ex+JgZVPTqT8US8zD2QxzKyymF09sN+F34F+7W97eubECR8RmdOk0qYyNNx7GX6k5E7LGe+NC86E5di5VFzM5SW47Dwp/hX9HazLGfTmUdOt0KH0qgEgeoS2fLGuff3Pr9MLuawfE1nVTGHoMmyf5B24dwl3/fYmRC3JcdVR3NBC5oCoepYLv7PdN+X85RHvlCWq46pRDsODKn3B3jUmVkX9Xb3dYzSW33MTF6IF6+aLEEzSxFmrNIInHV59H8/BjIZXBZ9Br9v/meglCp+maenL1pn+87APDQae12djur/frUYmQyzPS+xi99s+DMen4IFq7Kn/Fc9x0uem27+9v9320d4WcqVBgCVMIIa0tKrLd/a1wvX4vdPf+0rrFwaTY6drF9nWY8m7Bv6ylUv61jvMq/TnvOUPaGmfxCEtJ+jifi1Kj+trj2ZxmmPfokfeaYN+TyVLo3GfXwIGUSQ4nW3ysVy4E6czyfXQUt9VRQAsJJnjhbmvVat0ZQ/qhX7/vvVYt+X1BlOC3inoLkteg/ui/0TG5M6eaBsOlNO6PSxfd/x3lzPOnohOt0aSaO56NmvPa8BSLZ+R1WueXVW1pFeFNZoK0g2Xz9B89AnP7rqqJzASGR7iVWBCqtaOjw0GvW1P5u3Gm/PWo4/vaL2acmonuNzUxfbOsjzpZnfANCTjLnOGVnQSHd3+uNT8Or0n7HGJ/WMe8TsrSkrj7edy37Mo7Gb8HDsZqBtrTICzM905vWbymHIxjWNvyotNZSn6cwvc/an81Zh0pwVuPZV96z9SodGoxLtj0RvwtyKE111Ou2xKUozZGc1y148XFxEw4mFEv2sAJ1FC5oC4aXW56pyE9QNaY+QkY6/AupQSSbpNGozmULQ5GCkCyONW6J3YyQZkxpN05mk0dSSYiKp/NnXX+Vfl51DlmM2SK3l09VW+AdXMnj4MRxFqhnjqTSzdULZ/Bki8sfpJFbhNUjx6/R6wkgJ46XRBCFfH4DqAOe5tg3xtEcNi5WCwL/tBquJuaR0lqizfLJxq1Cl6BG4fTTuffYKW0ttyNfxCvZwhUDn+IDEvKSVTYZG45V6qJBoQVMgvnaYYwS5O1LtAqAeTbgrejuqyWgUNQ6fiGiK2TQaVeeUyyrMo2ghjgx/gtuid9vOtxGs2fcbrfjIlqjTqJfCdKYMYfW+NiGDfUOGtrQ4PDh4pcV1s21nLJCPRuUQ/nz+aqxosubgZHvcIhouiFbmJVBcqXOk75uHjCCIZlhzTuYsa8L8leqsTqpnsWRdq81sE3SJcXN/n7Q9Jg1LlMVe6ZWMehh/P527ynfBPdl01tiexAffrVAeJ6wQU39agyXr/H2NvmsB+TxKp5l31lJ1FguBfP9RD0Hzg5QsdM/QdPRIr1Hu50Xv6jgAa9E1r9RDhUQLmgLx+Tx1dhtnp7B76Fv0hHdjI9jTnlwYeR6/CFsz3KupXXGU0Rn4+QfUfpvgDevX4ff5MQbixdstPANrmRGBNjy0DOc/YzefFaLpPhz9B06NWOGYhU7wwOA9uc+ezcB9XRFC7LdPGJbt+/vlRicRJKuvV9/mvIa88uZIMjpweY8fV7Vg31s+tB3jd/WznvwKh0shybk6m23mUtuzkj53NHr4Dd1lYrDGYNz7cQ9OxvEPqrM+yOcIEXD+01/j5Ee+xIrGdhz34GRbxKJ4N4+85zOMv81rxRKDIFFnyvtxlN7pY6a+JXoPWMoyaao0MsAKFydk8Hjs77h96YlZ6yYjzHkiG7lqwbdCowVNgfDqOOROoRca8WTsb7greqfneZyjaNk0BQDVUAuaDLMateqdUJrOcmhXJ0TeNY7hXVSaMQztXYWNo42YzwZiJatDP6w1U8WrrpFvO94nbHXmMZbISXgNrKsIJO2ckWyEjCFmsmg0Tpy/cy2aMa/iBJwSfsNWHg4SOueBc9li2R8lggG8TKz5kHswgHys9bkWkmk1nbTtV4l27B+aiozC2Sn7iMRnZzuTkcOb53JNTpXJIp1hpl+iqSPlK1AzjKEv1mFHmuPaZlkVcn3HGEKw7vfI8MeobbBMxNnMqz347xlTPGu/Q50+N0uj8b1cp9CCpkBEPWaiy+aprUNGWvpRIfX8CIE8Cmpjcdu2GlKr+LLprKUjhZ5oxE5kNVrVSDufdhXlo/NMxojU6svWYDnriRWsHv1prWt/m+lM+JDyuC4AdLAIoiyZk8CKRUIBTGd2Hw0hgx8rjsc5iUd8o85UODvl3mR0iBdE/msrz3GZEhvOenRInWgFGZ1OBfzXmcnFLm+24YC/u12Hsb7VkmRWzSRt244LT8KDsVtwCLnz1gnNgwWsrxgQhELWUtzK9s8YVrdIZk+f55vOMLwUvxrPxa/DfqGpIElAyG0naGblGJJ4Ivo3zK843r5BqkO2zM82n2jbOtu2iMdARrZ8mFcia1uxKKukmuszsYj6wR529//Mz725ySwKnwWrYB9ZyCMeANiSFuB57GV+n/KT0bkbKWgMWhNp/Cd2I7YKLcCI9ieQRlg5Km1uT2HY5RP9bsvFSlYHwHiZIyFCT9aAVWwL9EQzqqndFX131L1WBoBEKoNhl09EjyzOeS+aUYnebC1WpIOP1qPhUNYX6OL/TMN0aenoH/nLf0zqFQx749dmeTBBY/8uNIw6R6BErunjZZzRb/KMbqHJZNNoxNUv/e83vvsBuQ8QVH45AKjz0WhElNyONBvPYzfb+V74yjAHZjJWmiW/ZyoExh2TrPVolH5LxrBaykO22s/vkwEGkWEefyh2CwDgyc+/wfHjhtp8HMOvsGfJ8srcfG7kRewRdkceRpKNAGoBGJOX/SYw10HatnoekgO3w8gr3/DcHwC2vvZt7DnSWApFazTrIV65teTOSWgjTuHhRH6JxAhVMDr0k/oYx3FbhRYAsNRr1Xu5oklthlOdPcEMu64w5Rn3xVCNVjShEq2Ie5r1BE08P5pqZn+23wQAiHcyld88EbDe3pqmjCxkvDgq/CEumHUMfhnyT6fiHBULQeOkU4JGUpNH9quxzX8wBQ0VznSW60DXptHYzMDegkb8Gn0ha8XMpjnIGo1fldT50tz7ZVjwtCuqcz431b6sRDLl3kf45JycF3lJWR5N+AcLyNg0mtU/+Ob/EzS1p1wh+EIjCzKQyhctaApEkHBV0en7GXOM9Wis73GHCaQeHmvCMbs/Ic2M+mwZWoC/RR5AJuXu8IKm1dgIqxEjoxHX8lFUhjFUUBIRpNHMqtCKOCrR4RvO7GWa+EPkWcyvON7mNBeI+TM3J4/GGlbLzxs8XC4SorxNdTI3R+9D78QS3BG7y3c/eeQ8EKsxLqTOV9YZQSP/jAz21CFC0MSL4KNxPs/Tw6+Zky9l7HOnJNMZvE1nop2L8GwAmBT7A56J/cX83os1gBapl8mw1VfRzlRzoDIZe2h6X6zDP6N3YTC5V21VvSsxZg8PTirCOFVPudonm0Y0uc783AOtuCV6N3pDPRCyaTTNKwK3c2eapFAXmM58BQ0Rbe/3r2i1Wg+JepjOZIRGU4GEbaRmxz4f3WkCqSO1Kj1raSOuf22W+T0FQwP5Z/RfODbyPnqvdGcVSAYczW0WMkZuczJDzOunMgzVzLifZlSghVUYEXE+zv/b3v1eef5zIy8DAM6LvADnWLWGC+cmVOGc5HnGecMVgeoNAEPZEuzHvDMqOAmiWfkhj3w/q/g9Lon+x7XPHqFvEGP+PpSgJNMZM3VIP6zFxiFjuelCBAP8e7LhS/RalvrK6L+NyZcO/ixNRpX7Z1u6onTC1j7iXAOrRQtujt6LWjRjRGgpdg7NMa/8D3Yz4o8fjHo0KbWsvUPTcFb4FaVQUC1cls4wW/mFkedwWPhT7BKa5dpXJbzqMusAAC9y055KmKmi2PvROvPz7xPn2rZ994P1jpwReQ1Hhj/Br8IfuE8Ce1/w1byfMWm2ejK3E2d0qtBojntwMt6ZFewcuZKtd7yF//sXgMkA7gfwAP/8r6LUaD0liInmmPAHAIAQMVO7UWF7ASWNppXFPTWad2evsNmY01zQVPIOJ5J0R+kkA2o0j8ZuAgDMZwP59RkyGYbnmo2wymZWiTbEUYV23zkU/5urDgFPMeO3Oz/yovkbCYSprolVYinrxQ8Inl/t8sa/4M7wLRgYcHFVZwddg1abdrAw47/Ud7a5SWNoPp6I3Yhfrn4wUH0Eh4U+wdHhD1zlyVQGrVzQvBj/k1keo7Sv0Azy5EUm7Vyjzlob15rRWfIo2RYMkLabT0XwwojQUhwV/gh/ij5pboshhcG0EjuFjDlIJ4bfUV730dhNuDz6jNIE5IzUA4z7kvcVpqihtByHhD7FCLLm+pDCL1jFjP1f+JoLGsV1VWHz/bDO/PxqZldckjzD/F7TbmU5GMI1q7WocZ0DsGuIX3y/GBc+O125nxOn5iLXMLg5PTd8e0fG2D6MsX0ALAWwPWNsLGNsBwDbwVoyWQMgLmk0u4e+xXhFXrJqyV6/EaknWTlNZ7Kt/a3MWFRQMpBZRMwMD/POJpx0CzZn9lYVm5GVBXkBG4AIZdAX62wj92ZUogUVqKU2W6hlEFX8nPBLiJBVj9Fk90EJgdyMSrTDiMCjZHBBMzhljMrPjLwaaP/fhg1n7teZTQEAvakRA7kTuDVUg3reWW5BP+HPkcdcnXm2e+5DhhlkQMcCz332DE3H78Kv2Mr+Gbsb/4jebz8XGrB5ao7poxHOasET0b/51iUo1kRbqywC7wSM90dvxXPx61CJdptAs2k0maRjQGVv01vSj+bnSnRgHz5hFwAG00rf+qoEY1JlOmPMJhzEoO7cyMu4M3YXJsUvQS804qbIfRiQ/tl1fHXGPuhTZY5QCRqRH/Dy5G8BAC+md8dpiYsxOTMKG/FnGIuETBN7lYefr45akGIhNKIGFR77qHBrNNa2IHkE8yGoj2Zzxpi5UAhjbAaALYpSo/UUWaM5OfwmLow8b9tOyCCKFD5KjwEAvBm/3DarHgC2p+9R/+Xt6DX/ZbMsjiTm99wDd+z+Jb7IjAJg+Gl2Cc3EndE7MJSWKesjBE0lF1SRlFujCbLI2Nvxy8zPMzLDABijTnkk+E1mEyzj2sZRIWtiYJBxsNO05Jw31JsM5+g6VoMEIsiAgFT2hJSCDB+vnRx5O9D+F0Wf59erBmBoOIPIeE6LYiNQS62IIoUrI0/ilMhbGEv2hKRm+hOFNhFCxrSrM58pk4/H/o7Los8ofVYyt0bvxiPpP2LxF4ZQEhGBj6b+DwCwW9iee+uFrxbnlYlZCE95Lop34AfDLmHD9FSDNlsUYi21oIXF0c6iRjCAwkcj2CJkDXCq0IHhvJ13sIgtkauKH5e5tVeVRjNlwVo0tlnXVZkbT428gWMiH+KX69wBKOnWBsz82fKfBF20T1znq8xI4zhEMCmzA5awPmZb61sTN5+/0LR2pDk4P2yFydehBY2oQjvFPYWRioVrnAFCVlv0miTaWYIKmm+J6EEi2pv/ewBA9rjIDYitNqozP89gw7EpLUGV9DLuHpqBEDHMYMPNsrEhyx5bgQ68EL8GOy+4G5t+fIFUnkA6HAcRYR2fgT+IVuHp2A04JPw5/hj5t7I+wkcjCCs6Z7/EkyoWsAEAjDDtTIahiWrwbuVBWI5eeDK9P1azHtgB1oS2fHyL/WxRR8Aw3sH8yAYAIHQgnpNG0xLqkXslALTwFC6VSJijzJ9ihpbzfvwirOPmjCGO0bX4SVWdViU6pLlG2V/ojRVOaRlRr/oFRkjr95nB+DqzKV5Lj1Puf9F/ppvm1VwejcrC2kOR1257+h4LKn4j7dNmEyY90IZGVCOJiCvqLE7ePqsqascQWok5mSGYzYaiJkt046wf3cYWlaC5/IVvbUlJnYMcEVADGCmYXOdsWYsJd1jzflTBACoznmgb7YjZyn9mvTEAaxBGGr2qY6YGKLT65+LX4cLof81BTE9qwlrWA+2oQBUFFzRzeQoblUYTJDVSPgQVNCcDmAngfP5vFoBTilKj9ZSNe1fhsG03AmCM8MPEMFpafOqJ2I0AgOWsJ3ZpNzID1JGlesvmgPbqQebnOJJc0MDs3MTET0D9Avwy9Cn6kD1MMqzwa6hePpkTwnYtoAWGE/68yAtIZRiiLIn2cDXfSpjLBtkmbeaS4mYNq8G3mWHoRXbNaxCtQjuLYiXqAQDtZBc0IWSwS8g+ct+YlpuaHiND4IrRvkwMSdukVhlh/66kDgyiVcgwwsLoMADAYFplaiRVjpRAYvSvEjRVaDd/nxjzFpZNzBByIoFpzGPyZYSPeMU5q6kdjawKU9jmWMNqzNRAKnKJMFKZouoUPsadQvZZ8z3Qas8MQC1oYpVIUYRHnVk4NRqZO6N3YQitwCLWD80i6MTBAaEp1nUVQlBlOnMi+z+X9tgKYWJmoMqmIbfpzHkdlUajCkL4HTfjtjOnoOmDCGXQD+vQg9qwBZ/K4ExWKyLzeqMJq1GLNornZDoTiNrKoiWAqzkvsp6WiMIA3mCM3cYYO5z/u40xVhyv0XqMGA18lxkCwGqccnhiHAmshNHpyQ1bFjTpiJUQsYISyHCNZg0zRudXRp4ytw8NrXCZWFQhuCqNJlsswFkOv0YHM9ax2Dy0GBmWQQwJJENW5oIVrB79ZEEjnb8Grbgh8pAZRcb3MD/9KXkKfmCD7WlKYJhNDAFn/LYdiIMkoXl2+GU8HbvBJmw+il+ID+MXoR/WojZt1EcEMchcG3kU/4lfj2FkOGBlv8PjacP8FEcCG2E1VqIOSWZNNBWCxmlCEp2yav7MZqHFZs62HinvRIjCDLkpGe2nl5QbT14uQfjv+vMopkrpt3o6vS9q0OYT3RgclUzqRe75HitZve17DbXZBFpfasBKVm9o2+mkbVtvn/x/o0M/cUHTFy2odIUHR5DCA7Fbze97hNzLgQdJgS8Pchrqt8y6v7OtqoIBVAJuZMjQuDoQtZUvYX0AABvRKhzU8Qb68t/4qPBHWFBxnLmf8PP1pgasYbVoRhV2DH2H/vBuU3+LPIBJsYttZaycNBrGWBpAhojcQ0KNHf6Mmk2zi9HZiA7DKEsghQiaWKXpWAaAej6CnpYZAUpYAiiOJNK8M/+OGQLMjL7i2Ds7tfSI5ODXsG7Hfq6E9GLEM+0IgSEdskZlK1k9+qABa1oSGHb5RNu65L+NvI7fRCbZIoZ68ZHZX5PH4rXMLmhkVbZR4gCsxgmRd800LgDQQTGbRiMmsIpRnmyu3JOnX1/DahCltGmGEwjTpYjME5mxr0meiIWsn7mtjlqwhvXAlGVWJy+Eu3N0LUwlqgmTT8Us53ydj6ARv3tPft/y/cvzTIQW0E/SaFq51rma1SFKaVdnKPj4h1XKcidfLVyLYx9wz10Rwq+R2QdFMrVoxY43vGt+74+1WI6epunsyHusya9DQv5mwmrqwBLWG82ocJnO/u4Ikrg++qjr+PMcyV6dRJCyaQ5r6tyC5urkyWhnUbyT3h5tLObSNFTBNc4yOejBaToT7/VAWoPhyXlY46GRGoKGYQCtxQpWj8U0EHXUis/iv/e8v2Mj72NEaCm+ilsRbowBf3t9NpY3WoOiUpvOmmH4aR4iojvEv6LUaD1GPCTRgCqQxC6hmThHmgW8BoZWsoLV2xz5Yo7NEtbbpn3EkeQaDQAQJmdGuezZsqDxctJG0rkvudzIqs3PVyVPQULKWNSbh2imyNJomlCJHtSGpevcc31EpygLL7HGzJTM5vz4Km6PNvYZE/oRTtodGo04rxgdyvcvwkjPTF0CANjCYWYUZi+hJYhn0IIK8xlWogPVaEMLKjEpsz2mZTYBYA0MnL+3GKT7zWN5JrU3KlkrKj2elRBewjYvaw+y5ivuvQ81oh/WYiOsxsKMISBX8cmtYvSbL17zKoTwq6U208zoNN9cHX1C0poZ+tE6rGD1XNAkbNsGYA2mcue44K30WNv31awO7SxuE2gxJHFk2PKT/JAxzM7uaED/+xQC/IvM5ngitT864r0BGHPHPk2PBgCsZT0wpuMhnJG8CI1mW7VQm87sZX2lOTSizR61w2Dz/ABQT80YkF6KGZnhUNEHDdgIq1FLrfieDcYiDDTumbKbB3tJ5nrGgPs+mm/b3pmJxH4EFTQvALgawEcApkr/NBLiEYkO+XeRV/B07AbsGTZU+T8kz8RT6f0BAB9nxmC30EzEkUAFOvCX6CMAgBWsp6l9EDKIUxKZUNxMDtjEKk1NQCBH4VQpOq+ZmaGIpHPTaPYNfYVRPPJn2/b78GT6AJtG04ebA9NhS9A089Ftj5C7kxVh1vKCXMLZLTS1RlaFMDFTs5DNIQK3oEnw8xq+mArJKTqQVqMlXIefmdFpOCe7ikgd4UgVwqGNxdHG7efbheZi9/BMbEI/AyC8mN4DgBXRdWrkTXwUO988Z9rho3krPRavpHcxtx+buBJTmCFY1UKAmZ2eGDH3kUyvlqBhhhmWC5RzIy8hRAz/yxgjceHTEss75ItXxottQ1a6+28qTgdgaYYCOYS/AgnEKYl1rAatqAQkrb0KHYhQBh9nxtiOX8164P7UBPP7OtSgA1GbVtDT8S48kh4PwJjlnwsDuFb4QGoCrk6dinTYaMvySqU96gwhyRBCE6uyzwuC2nTmDAawzebn7/TwPsaArgHG311DMzEotch8hk76UgO24oOwWZmhWM1zo3kRdYWiG3VS+d6KJGeCCRrG2GOqf8Wp0vqLmREXIXSwiE21/ig9Bs+n9zIb7oeZbVBJCWxD8/DLsGVCWM1qEWYpRJHC4SFjpJaJVJjnbkUFomT3ycimBJWjtJFVB9JohtIyXBl5Er3RYM74npUZinVcC5M1GvFiyoJGRGpRh3tSqRhhZiTXY39aiyZWaR63mneafX1G4e0UB5LWPcbIeImEw1zOWjyA1qAx1hdrM1UAgBuj9kmSQru6OvIEAGaLBhJzdsaHvwRgjQSd5g4AfDa+cS4xp0WMuh9MHYzbU0eY+y5nPU1fRj9FZ1iLFlRwjVWMmAdK82Nq+PONII0wMXyU2RoAcHTYCCsXQvtLriX6TQwOwntz1CatLaVAF4HKXGiG6PJ6NKIaTaiyZRsWdVzBetqOjVPK1MwAYA3rgXbEbIED8jv2i46/mAMEvyg2FQO4UBT+sUzEeP4ZacHpcEQaVClMeKqlCJzCx0/TTSCKFhbHweEvUMlasZLV4+LEWa79+nBBk2IhzGJDTd+pFxuR3UwqfMNBJ5gWgkCChohGEtHzRDSLiOaLf/lelIiOJqKZRJQhorFS+TAiaiOiafzfvdK2HYjoWyKay013xMt7EdE7RPQD/9uTlxPfby4RfdMVKXPkNdDjZB9FOEcdi5gxw7w/rTU1AcDqyOJI4NaYcfsZqTM/UIquEdg1GmN0fkbiQpyeuAj3pA5BC+KIBtBoLo08g9Mjr2Nqxe/MshbIyxRY9yfMXqujVoRcMzP8A5R0C5qhtJzX1dI4+nEbs2AR94u8H78YN0QeUtZxc/yEiuVTuYZhmY/EX9kJP5DWoCnWD622e7AQ2tWWoZ/QA20OQWM8B2eYeLvHS+1c+VSM7tsQM00igKH1reIRcM7IQMBy7ANWJ7qRJGhijvudnRmKNhZDJSXQyuJoRhWvdwQ/ZAZ5Livhxy6hmTie+9Jm/qxy0jMMdEw4HkPzbRqN0LT+E7sOgBWh1cQqjZF7uzWYEJptE6vEi2krc/OszMa2AIO1qEE7iyFOKXPgUsc7zdMSF2MG28Q0R/lFsakQkXtC0IjJkimEQNwkJc+V60As58SlMSSxGw9aOS7xR+U+jbDM1StZHf6b2cO2vZUZyWu3ph/xAxuMdsQxG2oTm+D52DW2778JT8KCiuOwxRx30FCpfTSPALgHQArAPgAeB/Ck7xH+zABwBAxTnJN5jLFt+T9ZnN8D4HQAI/m/8bz8cgCTGGMjAUzi3wHgIGnfM/jxRcXvGTnXlRGjt3601jZ5T/WiGKYzg7+mrOgTMbNY7oiE6awFFXgnMxZ/Tx2LNsTRr3kOfhv2XxIgoohQamJVyn33DBmO9lUVQ80yEf6MDvfkULFW/PmRF0xVvh7NZsj2MWMHYx7byNz/N5FJyuvW82VrRSitKWhICBrr5d8qtADNsf6wB3DKKXKsclmTaGdRJLmAER2qmGir0mgAuNbikYVWg9R5NKMSq7ngUUVuvRO/FACwltWYg4be1IjFPCLJKWg6EDV/d6dAbUalZzCAFyNoCZ6O3WCaclXUosU1b+PV+FW2YIuPuaa1Q8hI1S9MRo2oRhOrBlbONiPinotfZ9b/4uTvsFn7Y9ix/W48lD4YS9HbPOda1kN6P4zfV5hDhUAS5l2vkHAvBtJqJFkYq/iAMB022v3yyCC8yk2fy2LWMuJtLJ41Q8dmtMiWJuaPkafMCcHyeyX3G7Jp2bgnwubtj2KT9iexefujWIsaVCCBYbQMc/n78iMG4qHUQTyVk11L2ZJ+NKPXBGKS9BnsOVedS+2jqWSMTQJAjLGfGGPXAJiQ5RhPGGOzGWPfZd/TgIgGAqhljH3OjJi8xwEcxjcfCkCY8R5zlD/ODD4HUM/PUzTIR9I4O4FGVKGNxdCf1pkdykEdfzNfJHkiYKKil9kYn07va5Z/lxmCVhbHKClNjNAYZMHWwjWNq6JWWLQKlX8n4jE7fVjI0FCSEeuFaeYvjxw1BxhmMzlEdwce7dWD2tAojgFhDWrxj+QxvnUUiBdVvOw3R+8D4DbftFT0t32X1wKShUYdtTgm0tmf5elJIzTUad4RODv0Sv4c2hE3/UeA0Q7W8M7M6WuTWcHqUUkd+CR+Hg4Kf2mGtse4kJYFTSt/1q2OwUwzq+D+weBzZm6PWikMJ8auUO7TwyP7sBh8AHa/ACFjameNrAqNaaON7+jIqmAsChBCAmLeFJmz5wGRhkgE2nBBwztyIcyFeTe7RsNwfvi/Zj6zAbQWK1APxrvEhrrN8LvE+bgl/js8ld4Po9ofwdpIP/PodsR8F5cjZPB2/DI8HPuHWSZn8pbbnmwJkYNlOvi9dCCGDELoQAztzNCk+vBQcQBobEtiOatHhDJmcMq2NBcLKo7DxPiVWX4HR71L6aMB0EFEIQA/ENG5RHQ44JHprfMMJ6KviehDIhJ64yAA8uIPi3kZAPRnjIlMdMsA9JeOWeRxjA0iOoOIphDRlJUr/fMo+eH3kNzmG8Jy1hP9aa3ZKa1idaa99dzIi+aePw/Y12yMskO+HTEsYz1tc1e2pnn8elaGY/mzPOemGm1YUHGcucZKTDL3vZ3eAQDwbsbf4rjXFkPMz838OiGH6ey48CSEpYgYEZ1UixbDXg9rcqeIyhNcmzwB+3ZYGYKf6nk2PwdPh++wxTsjn1riRudwExdgQjDVogWDaRU6+NyYWmr1nLENAHU9jHp9zTZ1bQPsK5+OD31h/qbOSXkAGbZ4VPpGhK1g9ahAAoO5fV1khYiR0OAS5vmFRtMiPWcA5sJawn8TBLGOEWCYFFVUesxCj1LaNC2ukibI1qJV8tFU4d/p/QAYWYzF3I/FrA/ez2zrOmfCNteEJNMyX1aA+86EebIjoI+mB9pwYfS/eCH2ZwCGdp2KW9MGQkR4I7MzkuFqft24zazUjqjnWkOAFcBhZf9gtufdLt2X3G/IguYHZmlQ1nEx1KMZNdRu/sYZBjTw7lj8zoeHP/asm5zxwEmpNZrzAVQBOA/ADgCOB3CS3wFE9C4RzVD8O9TnsKUANmaMbQfgIgD/JiL/kAoJru3knPiEMXY/Txg6tm9f/+y8fsiPKM3INHcAQBtzp7YfFlqOQ8OfmmalVsTRwV8kMRfnpMRlCIXCSiHWjhgYCIeEP8ebMSMn2cVcNZdnhcsOUzknkggfPplPIpRHgX9LHYet2h/EE+kDbNc8puNq83MSUUzYxjJ3iY7OqdEcGDIc6n9JGulJhG9C1mjEdIPXpAgtAHg5vRvmSya1TyoNjU5eckHGGfnUFDfGHcL2LUahv+eCXPjS6tBsakPOiXQA8MllQpNUv4hymPO9sX+anXwbf557dtyGkxOXmvssCQ3CplJ2YMBu7lmBetuzauLt4bzIS4ggZWoVragwgynaHIOZ8xOGUHZex8kVkafwffwE26RAP8RvfEbiQlyaPN227ebUMRjd/rCtk+xJTaaPppFVmesK9aQmHBU2rOcnJi43tQknszMbm5/FQEw8q57UxBNLGu0oqEbjXPl0r2GVGNjPel/FU5b7XZugYf4+GmHOFu27AgmbT849ALFf9+kBl9javXkcYmYWa7l/aeBTEYQp0WkGvyZ5Ika1P4LX0jvbBn1OSp1Ucw1jrJkxtpgxdgpj7EhujvKEMbY/Y2wrxb+XfY7pYIyt5p+nApgHYDMYmaJl8T4YVvbo5cIkxv+KMJklAIZ4HFMU5Ge0Rcej2KfjVjTwhiY6CpkMH1mIl60NcbOT64UmpBnho8wYTwfdalaLESFDmRsVWmSzGa+VNAN5JrU8ChvEk3ou5oEJ8vEtrALNqHK9/F+wLfAtT66ZJPvL0sKDGpyC5ltmzD0RI1ljFjizaTQi820TqmwhraIDETRxgW0435ktIzbgHm23xAyNxmnbHyFNogWAvUPTLY1G0QmolupeLjmq7439E9dFHkG9wxwmRuALWX98II3YfwwNwQhHWhM59HUl62nzg7RIASPjQrPNZKNrWA+zk2lxDGZezuyOJay3bcKnijMjE82F7bwYSstwQeR59ESjmRqlCVVmpKBgDeuBVlTgmfQ+Zs61XmiyRZ2t40K/J5pRT81oYXFlpyr4ZeIv2Lz9UQCW4BbBFz1NP5/IHJE9GKAS7fhL9GFbWTjVCsQsX5p45eR3T0442Ya4bwSZ8O01ogrnhV/AN/Hf2rZ3SFqzHGYsNJrmSG+oqEKHqa29m9nBLBfvifAJObOFvJneEe2Io1Ux4JXxM/93hqCC5mEimkdEzxDROUQ0JvshuUNEfXnKGxDRJjAc+fO5aayRiMbxaLMTAQiB9Qos7eokR/mJPPpsHIAGycRWFORGmUAUSUTMjlSOPBIcn7Rs4EkW5nZY40XpSw1o4h19OETKBuDshOWUNrLJ4erkqebISoQ/b0XzUc87IGHbl19OpxlGRvhi0iH7yF8I05BD0MSRRBOrRCsq0Mri6E2N6IUmxChtRp3JoZbCrNDC4khJIdUAkGARZEIx1FAbatGKOCXRwSKmCcz58jdzH43TpLJveJptv2Mj75taSavj3vfr+AdUHN5xnak1AMCJkXfwu4iV3j/Bwjb/jEwTql2RanLuu5Tj1WyWBip1aDF9XqtRi295otZVcCfvWMN6eK7QmAv3Rm/DBZEX8HH8AtwUfQCAMNvZB1A/MeP3ziCEB1IHAzAmINZSi/GcEEUKEaxkddgytABV6PCMChQkETE75pn8XncI/YAqtOM3kUk2f2RHgGCAI8Mf4//C1jRAIoASLUA0i6CRXsEOxFBHra6BhcDSaKpxUfR5lyD3CioR0W7piPr92yJkTTqW26lLoyG7RrOMB1U4f+sdaY5tcmtJTWeMsb1gLAtwJ4B6ABOJPBZUCQARHU5EiwHsws/1Ft+0J4BviGgagOcBnMUYE9c5G8CDAObC0HTe4OU3AjiAiH4AsD//DgCvA5jP93+AH19UVI9IhC47fQ+APTeUmBsjTAN9aZ3ZeIi8DDaEkxOXmN9ejV+l3GsV6vCH5JkAjPkP40Kz8Fr8KpzPzUfWZEerk3aaYWz3xDsXp7bTjhjSjFzhzXEkzA5gNatFb2ow54aIyZTyxLZ23nGo6pDMZMCildwUYXSgP7H+iJMx98hpOhPRQ+L6TkE0PzPA/DyA1iDBwqaQ/VvyWPw9+WvMY3bX3lXJU3BP6hD8jD6YmLFnSpa1Eq/OBDB+Q0OwWfctBgpnJi50aVxrpIFKJXXgtIjR/FezWjyZOgB/TR6Lj4df4LrOQtYPO4fmmGHAQZBn6BsjY2am7a+R5mm1Im4mADWP5ZNRAavN90QzatHKB0ZGS34/vS12CH2PKmp3RWT6sZj1RYqF0IcacDqPohwSsvyqpkbj46Nxan6REAHJVrCYFAnG6+m1VksLr/O0CuO9Oir8IXYNWSuLivaddAw0zkucizMTF9oGgvK8STEoaIwNQC6IQacQNF6C1vlOPRe/DudHXjC/l3TCJhHtDuBiAFfCiDZ7DcA5+V6UMfYiY2wwYyzOGOvPGDuQl/+XMbYlD23enjH2qnTMFG56G8EYO5f7Y8AYW80Y248xNpKb69bwcsYYO4fvP4Yx5p6AUmBUWofolDPM/VM7GzxgvSh9qBHLYDgnDY3G2mf/jptwbMKIJpmeGWGWiyVifyX5UQRi9HNX7E5swpNICt/NbyKTsG/oK2xEa/BWeizGtD9omxHtRPh/atPOsQZhJeoRabJ3knEkzU53NWrRB43miG8pFzSyRiPMIypfSSrNkIlUohId6AshaIyXsgrt5gJnGUa21TC9TCrHJq4y/Qyb0FLuVDV+7PvSh+Ce9C9ddXgyfQD+njrWqA8iOCdxnrltGymzdoePoGlBJcLE8ED0FrNM5L5bwnrj04w915asrVSiAxmQOW9mFepwf/oQ/N9OW7uuc1/qEFRRB34R9rV02zg5Ya1BNIRWeK7q2oa4r+a7jgtH4aORQ3qXsD7oQ42oRStSkSqvU3hetxIdiDrmqgHWQO3m6H3mKp9OnEJodGgh0LgEoRZLYIn3TX6n5XdQNk1XoAM3R+/Dv2N/BWCENZ8eMRbQk9sDAExnm+CtzI6e9yayATTE1YLmmqSxqu3qHpvbysWgVJgoxTNbzPpgm3YrF1wzc5vwt+EBREDp16P5AEbY8P0A9maMnc0Ye7ooNepmXJk8FZ+kt8R07qeQWQ53qKw84hATGENENo1mLhuMz3hHJE/wAoAP0ttgMnOvSScySgPAX6PuyZD3RG8HAAynpaa5z4uXMrt5bpuT2Ripn+3Zcw3zltEBrGM1qKdmM3xbJK/M2ExnXCgxdxzIt0sakA5XoJISZt4ocY4qdJjO3S07HsIBiX+YnYM80pXt18vRy7zOiNDPZnRXLiyRnLKyaSPjoYcCwPI2Y9sB4a/MMqENrUMNnkgfgEdSB5rb5A6iEh2II4n3M9vYzqnqI75hm2B+ZgBuiD6M7el79w4KZH/iB/GLXdqVYA3rYfMdqc6TYiHDdGZqNAYreIe6Ma0wszAEpR0xVCJhy6YtWC0J5FMjb7i2A+7JtSeFjGCYUJNlWVcNGuUyeSKvc02ik8NvwgsxKPLi6MSfcEriElDYfW8A8Gh6PM5JnIf/7XyfrbwJVcgwMjWaPcPf4qP0GOzecYcZkQZYFgQZee5OqYMB+gC4Doap600eUXZ9UWq0HqN6Rt+xjXF88krly5RGGJu02+e9yh2dWEPFb7ZuGmHMzFiTJh93RImZ50I9nkvt6XkeMcpz5gNT0egxiRMAFrD+iDUvtpXFkTRNBc2oQDXaMYRWoIlVmhM2kzbTmSFoVinWkAGAZa0hQ6PhgkZkWZAzP7ehAh2ImV29OGcFEqZW83F6KwBGskbAWGdmmcc8GT9UgR6AepVNgSq0Wfz2xu9LuDZ1EvbquBWfpUdjcmYLU1Otog5UIOEyzakduYQfmTF97IX4Ndlvhh8zov0JfMaTSd4e+5dyr2ZUufyEzvOsQw3qYfhoWqjafEeEcB9CK9BG/g5qJyLiK8zNza+ldza3yZp4FCkcGfoI78UuspmSnOvIHEFGPri2o6x5ZqpfUu6ExWqzAHBxxJr4OD70BY6LBM8vFwuHbMslLGL98X5mO5DPIGViZhyidXaBxRDiE3RbMIYnbRmg8G6Id0VGHhCVNDMAY2wdDH/HjzBCkEfA8KdoJPJZUVK8GPMyRmcgzyIXo/AQ+UeDvJLe1fzsJwSCtKE303a1fmCduxNocGhRMktZb9RSqy3SLY6keS+trIKvmLiCR7sZlZI1GjFjfrHipQDAF3oyfDRJFsZyLhx6K2bauzQaJE0/zTs8ameVlB6Ijdjf8968kLNcy6gyLQhmSR2VQEQEyk7en9gAHJu8ConKvpjMtjDSzfDII2eOK6/Hm4R6dKwiwYyRehphHJs0fH5iLs99UjTg8QkjkKUDMYzjC/mpaGDVqKMW9EAbths5FL2qYrzcGGBUUBIdHoKmf61a02lDDBXoQB1akGIhXJA0rPjjt7R3vjGkcEvsXmwSWob+UqdbhxY0siqcmpYmpO59BVBvaf2m6QzAnpsZ7TAk9ZYz2Ca4N3WIcV2eDw8wog9zIRImZb+R7V2tjrufaQOrximRt3BI+DMAwI3cvAsAv97RuDfZijKbWznkSNRQUNUjR4L6aOYDuAVALxipXDbnAQKaArBl+0M4OGGsVZJCBEn+sieYEDTk2/Dkka3TlCbjN8IGDCfwdakTs9ZXdBJL0ce1TaypIY+mZEHTYmo0K22jK3klQpGK5q2MPU28IEnG0rV90YBVqDN9Oqf4mCxkQSM0GpWJLhHNfennlYpoL8AdYirzZmZHvJjezeZMr6QOJFnYFWkHWHm2WmGsD1+BhMsH5NVJzGFD1Bsc3JeagG06HvDc/nJ6N7yU3hW/T5yLT6RMy8ugDsUFjEFJHVpQSy3IxGvN0AdZE2r3EDReAzfDR5NAPbVgIetn/l7i/sWgTQ517yNlpuhPa7Gc9cSX6c2sk/be1CaoxcieKcoEKh+izEOpg3y3A97ZsbONCVWCRuRkOyMyEUkWxnuZ7cxtIppsjdTWj0hci7fSYzE8tAy90YDTwq8j2p53jJcvQeXXpoyxgxljf2WMfcIYyy2bnMaXFlTaOg3LGW40pnDIT5G2N3iv3GSAXdCImf8AcFvySABGmLNXOK5MI6rxh+SZeGy0kQ25Z1VU2mZcX05T0pfWmT6Gdh4WunlosS232W4jLKH1QWY7jG2/B/9zpI0XJEJx03S2ktWZv50IWb1MmkQoNMF2M7w5YU3M5IK8TdIgkuHcHNP8KngkdSCuS55gK/XTaADCYtaXjybFqpwJ89k7iYWN+2hkVTxdTtIlaMIekubO1OF4Ib07APtcKSdNrMr2Wzj5mfXGBclz8WpmV899nAifXC1aweJ1pplI1ry9NBq5kx81wBoAGOlfEqhHs83/IJ71cTxQZseQ5ZOStd0BtBbLWE80ZeJm9BgGbuuYoS/Vg9fZKWicKX+cXJ86Ae9I75lMdcx4zw7ddpByhnm2+SzVcfd7Kk8aNsy51jmEQJODN9pQge/YYAzEGkyt+B2ujj6J+vlWeH4hCSxoiGgSEc0AACLamojUsbQa/GbnjV1l2w6pD3y88OcIvwYRfHVp+aX1s5mHpCYt0sivZLVmhz+gR3ATy/PpvXDhEYb19NPL9zPLhaATdvB6NGHT0M/m9eQIl2k8Yq62IoLjx1l+JsCIsjp9j+HKaydDFabpbCWrd02wXO5YUhiwIsA2o8VmWnpVVFh+gga4NnUSHk4fhMM6rsM/+bIAYYegeeHsXfHFH63fqo3FEKGMmX+tEh2ejvEonzC6Dj3QE02IU9KWxgSAaZZykkYYn3B/lJyA1YkzU7XMs6m9zeUiVBybuBITOm5wla9DDUbTT6ikBFhFnbnYmax5t3sIN1mjufoXo3HQVoZprI3FUUNtqKNmrJPMluINWQ77CrSA3SfWn9ZgBTchnZM8D5PS2wG9R9hzjkmmM4FT+RBr3/iR9uhiP7lsX3x86T645pdb5mU6i0fcz0qeeyUvcAbI0WTG3+l8Ab8mVmVbMK11WO6m4yAEFTQPALgCMGwOjLFvAPy6KDXqBgyodb84NQpV1wuRL0poKtk0GjnU0i/c9K7UYebnF9N74OzEeTg8cR0mZ0ZhSmYzvDv8Mtcxfn4n0dgrY1ajF+HcIrJHjCR/5pFZn2S2MvcVCSp718SVTsh+PdT3kqQKVFIH+lKDkR/O0eHKs5+dPprTI6/jlqix/IKzowbyFzSCaWxTTOQz4mcz+4CjrjKKflLbEEJF2MgrKGGup+JEmM7WsB7mWkBOAdunh3c4tehY+ygmb6Z46P2LXOtRcVnqDM9tAPBZZktzMqVMA6s2Jw+yeA9TO2hGhZkZoyPk1WatxhcNh7BxL+PZzGJDsQUtxCBa5esvlOnNTWeEDPphnRn08UFmO5yWvARwmafd7dHZRhNZTGeAsfzz9Wl3tq6KaBhDelUhHCIzz18uqExut6aODrT/1u3345jEnwDYBf4FibORqRvqOrYQBBU0VYyxLxxl7iD2DRzRDiPhznnURIhzUB+NPeuA947fsyEY3f4wtm5/AKtQh9cz47CY9cNK9MRRiWuwrkatQeSCU6OxQnaNBn2vNC9FTOjrUxNTVtvrnuc3GFlq+6ABK1Hnir6apkh8Ke8zMmRkIrKnATEulox4h+sG5Qc2CNckT7TlNgOAuCONjRgU9KO1OD/8X9Sj2XOirBA0a9HDrL/zvntXe5tyxJwtZ3r//UNTEaEMnk/vqdQE9u24GWcmLvA8bzZkQcDi9WaXyqQsGJ6mM6n/lQNi5mSGIEpp9KVGW2i5H2N5frA+aESEMua6M15Y82ikOmSZY3Jy4lJTmxWsRE88xQ507SufVzWYyxb9FQm7tz+d3g9HdvxZub9sVm1Ejdn2ZR/hF5lRJU+quYqIRoAPMYjoKBjRZxoJoXd09lmZgkY4OYl8wx3XKNLbeNGKCs+AgZhCQOYa7Sg0GjFhrJ6r8CJsWw4/XctqcNNRW+Oe43fI6TrtiKOOWhGhDEI9+ttW/nw+vSfqe0h2e/67OWdoA8C4zSwf0bWpEzEnMwRNle6MublDeDQ93mVqcpo7hInv7ujtuDD6X+wbnuaZTUD4aCZnRpllkzP2+VKxSAh3HLsdVIjUI86lIB6MGRNG13rMH5rPNsJbmZ1wnMMcfPCYYDPXGyTTFquotXWq4pl4BgNInyPhkPlerZP8MsujGyv3d7JPeDoAZkafLVeEsduEiqJBqt7rS5KWpvdRZmtbBKh5XCi739NVlyzbIx7+uKlsczyV2g83JI9z7K8+o22hNdSXfOGzcwDcB2AUES0BcAEA9xqjGziqUZAgF/VYjDKSpqDx7/BVOa7yQSVocg3ZbkQVFmb6Ykc+ghQCR+4cJqZ3AmBMMjtm7BD08TCdeSGbl3bbZrRtjZheffrbVkK0Tus+/+6jLKHyWPpATEjdhEQk96izoDgTcwpz4mYhK9drA6tWdgrinuZlLOEoJqrK/FLKpi0jtKetpZnq8twSVccrs+/m9mvtsol3pJnMU2nJ5i8FAwDWoKMjpNYi5X2jYTLbiDywim45wTRVy/vLaXQEVegwzY4qjca+LowbVRt9K21ERj6YOggZhJTpdMJE+Cg9BlclT7HOL2s0qmtlGa1GFRqN4MrUaXgg/Qt7HTzOJ08ETiJStMwAgRwHjLH5APYnomoYwqkVho/mp6LUaj2lUI9ILIwlnNbZ1Fm/dDG5EI8W4jyEGWw4RvLU9CKtiuy0vSB5Lq5JNttypeXy28mJAZOVfZEAYXj7kzgl/BYa+hwHLLJG7b7njVQCUm4yoHgLPwFu05lIQCkzgNYgHCLXeu5C0MimqGzJKGWE3+p3kVfxaWZLDKTVSDFrpO01OVYQdnZsAX+oBKLoYBHEKQUWrwWTohHF4mgNoXrlsfIvEFNoNLMyQ9EW7gHiS0ZIEfI4LnElvqs4GQDw79S+OC7yHq6PPowjw58A8BA0pP5slbkLG1GDndr/ZS7Vvoz7wr7JWGboUIhwYod9ETnbAE4xmsv26+Zq4vLSaJxtqCS5zoioloiuIKK7iOgAGALmJBiJKoMthbgBIdphPhM3ZRbwDijCZz4TUdYG8JvEFTi640+duq4qkiWfjlcs6AYYGYkzjGxpbZKImDmdcrnOyH5GByP7MRKVhlbAEMLD6YOQ9BgdA7DlPgMAROwvGWNMaaK8YH/36DhXNutf4xI0HYiZy3EL5oU3wSUH2vNYAdYgQM4c4bV+iwq5Q3kidiNuij6AW2NGUMS0zAjbnAsVztF8Lh2SuappRZ0tJb5wpjeE1NqU/B5FwyGzo1/M+uKa5InGGjaM4bpDt8LgnpW2YAjZ/ybS3QghA8AUDDLyLamsE16u1xXoaU4LYAhh2/b7zBBrwP5bjexXg036VNusB8ruIsvvG83RD+waKHCcgqZC0QcUgmy1fQLA5gC+BXA6gPcBHA3gcMaY3wJmGyTiRVA1nFyEz79Sh+GvyWPxdmQfANkzAwDA/zJj8CUb5btPNuTG++wZRuRUPkJzBeuJWmpFFdoNB3ekR9ZOMYjp7LDtjCzKsh8jVek2H8nIpxUzyAXMkYrd61Yv2H8zjy3BefvCvdRJVx25wg6++GHsPNxtlhIT9IJGWTnxyyT999Svbbb68/YzBOv5+1kC1ilY/OMg7YjwWVZRZ2tPP/Cs2C0htbnSZjqLhKQ2YvjAVsE43wGj++OTy/Z1+S1EgMf3GbffTTVfzJ5AM3vUmRfr0APN0sBKdsQfss1GeO8PeytNVMN6W8dkDQYokEbjNPXVVWaPpMuHbIJmE8bYyYyx+wAcC2A0gAMZY9OKUpv1HPEoO6vRJBDF/elDkJYmbBbLSScjD5JytdXK1ZvHc2ttTovQlxrQGirMqt/iN5AjjdIx/3PLHeJXbDNbokqnRgMU13SmotkZjl5Rp5zh34MLGlXWgGCQzUcg40z1r5qg6Gx/ufxOb/C0RhSrsQnzcxLn48/Jk7AiMlB5nLxvNKSOvJTfNeZ48Y5K/BlnJ87DDEXYtQry+CzI9x2U3yvVGUS1ZXNYoU1nXnV3mc5KFHVmegsZY2kAixlj7T77b9BYGo1b0gysyyNslj/zUADTWSGQO+UeFUaHts8of43BOtbiGz4Z7PboXTg4/AWWxYZlPT7ISyxeWJFEdMXQX2Z9IZ2nvTZlzWmgqLODLZyfLSiutO2RmDKiSE45cl9qAp5K7YfBPXNrU0+m1ZPxnMJLdHxym3P+Lpv2Cz54uCB5DnZuvwuhENmEwUrU47H0gd7ausN0pnoH5HfN+dZ9xTbD65lxWKjwhamw+2jy12j8jvM7xYi+1m86sN7/2ea6EqaXRuOn6RaSbIJmGyJq5P+aAGwtPhMpMhhu4Pj5aDbpm5/JAxCCprBd4L9/uzO+uHI/W5l8idqKKP53+b647tAtEQS54S9DL6xkddiYL0j1Q9W2WY+PRULYfuN6333Eb9CIGuzZcRu+2/Um35H282ftonwWzWJCZ7hrXrKrJriXbRCoIgZV5vdqaVLs31K/wd5/eAof/GFvvH7eHq59rzjIy4SqbkM/OaLXhB/Fr+PdcZj/PJSjdrDMVR2IYTl6gUDIKJ5HkLYdjYSUnatdo/E+fnT7w2a2bi9spjPFNVR9dZDoO7ugUdwDF5FbD7bawtBeVfj40n1s+13u8Vw/vnQfV93k9gIAYQ+fjmzS/upqdeb3QuAraBhjYcZYLf/XgzEWkT67vWmagiLaTihUeJNOdTzimnnvHHkNqq8M7HR0dPc2c4zXhDwn2UZxcv0Wsv6gUNT3d6mtjCKt6H0OSdyAS5JnKM0ExTCd1XukhgGABWygKyBA1fFWOTJLDKqvRCQcwuiN3K9hr+rgAnRCxw2u/GbiF/Na9CsISm2L3OYtUa7CZjoLq01nsuDym0LQigrcnAoev6S6lqq91FRE0DvL7501apSJaxKG9Ko0rz+klz1LxSCP92NIryqXAO/vyE7i59OZltkEN2WOz6nd5EqRkkJvmIhn6XyZYuFQXh2YeNHDndRolC+NyjRgsyV3rsfdJLTM/NxJl5WJ6l3xq2eI7EtEC35kA/Fcem/lb9DZ+86HZ9L7okHKV6cynbUmvDNBO8nFfr9GMV7MBPDRZKMyqo5gVAldr+raggFCIVTH3P4pObmkSluSEXOJUorVbt11KtwgxOZ7CXgOVTvM5Rk4haJfmzgs8Rc8lPmF5/ZCoAVNARGNwzloe+MCt3kDyN7orBDLTgoa/vemI62lfrMJn1wv57+//QfZbdPeuPaXW+K139tza6lOce/xO2AENzs6XxYi/zBbIrKtc+OkUJ3JL7ZWO7NzYfeOO7BH+h4AdoF/y9Hb4NZjtsHk+d7JMJ3kImjWodocRQuYOcIG3rxgD9z2q21sv4vKXOfk5N2GucoIwOOn7uQqF89hn837YrdNe+OaQ0bjzQv2sAmOUIhc2QkA4NLxljkpWxCOSHmzxhHa/NxZuyjravy1bly1+iQh+HvsPJ/AnmqHXMdY2/yv47dvtii1zgYwZUMLmiIgP7PDtxtkc/LJZFs21TSdZelQsyE0ox2G9bSuneWEuV7O+QKJ1BwdLIoZlTvbtj3123E4addh2GpQ9owG47cagG2HGPV2jtLIo6Jy1JRz4qPt+AIpL4fzsOvO0IQqrCHD7yE/m1EDe+CI7QdjbWvwlTn8BiUvpnczlwwAjDlJE8bYswkI4RwiYNSAWhy+3WBb+1OZ65zEI2GctvtwV72G9HQnLRXV3Wuzvnjqt+Nw8m7DMWpArcsUFg2HbJrSzsN7OZLV+veWK1hPrGR1uDJ5qq1c6W8KaAUIQtABHJH/e5dLRJizrtne93wSe+ZCvrGSGgWqYABzhKJShUPkq++TObqhnKNMbOdx1MX5WVmWu6Sx8Vx6bzyX3hsAMD7SD8Ay1yFZT+l8WZx1JkXYrfTZ+HmLL2hUZiKvOvnuJ5lKBWbalZak8hgVfp3KhXwu0RHm5EX3vqJJ2n/b3H8s509PpD6NapEx1fFOOlL2ZRiyazQx7Nhxj/9OHPG+2gMiFPsF+FmSaf8FB1WdvOq0uQg6Zxvwyo0myGZ27Cxaoykg4tHKDeeEXYxQ3PF8LQ05ciSbRiOfN1eNJqR4QeQy1flsI68sHcsfDw4+OTToaEl0tM66iePdGo1/LbNqNIqj8xHo8SyCJiji0nInIZ7J+TlkJ8gWEQYAh3Vch/MS5wJwPx8r6kyuR+DLmzjPS/DPQu6Fl7P93H3sWboLaf6R71fch6ptGG3I/6bak5Z/Tfk7ClMlpAFlANPZpv1qcM4+I5TXPG8/e3tRZXuW8RuQFQKt0RQSMTKTnplY8Gx4n2osuNFYc71/bRwXPjs9qzprFxbZ39CDxwzA3b+xVvQbdvlE41gQAJY1zFIlnLw4Y097A/fbPdc2TETKg1ShzNl+l0TKezSpHKEGq6INZ2qZfBHtQW4XIuhv/JYDcPVLMwKdp2+POK795Zb48yszPfeZxjZVLqcgk2v7G9KrEovWWLnMVBqN6ixe5xaHfyiF+Ypd//3bnbHrpn0c+1sX3Hl4L0z+Mf9liVV1CjowdNImBXIofTTmNdW+IYFzoPXuRXt5XnP/Lexzh1SBFLY6aI1m/cHSaPyRna3Bzug/ohR5kzwbixgkZdFoOmU5K5AZClDUzeO+sml6RLkLmnxwZmXOFyFI5Q7FMp/mdi5lGHFATI3GVrfsxzkHAs46eA0MPE/tM39F7ZuzX6szqI7Pd5kp2cTn66Mx/1OTi+nMuWeVYunnrkQLmgJitoMsL7mIj99mcH2g85HCFyEjEi56XVYcmc1Hky3Xkx97jOzruS3XLs/LIOYsNXxX7jIZX0GjNJ0FqiIAYBuurRZKxorzRBSms1wd0Z0ZoJoTFBX18MO5j9Nq6WXqFMEFw/rYJzWbJlPpvEwyMznZUgpS6GyYOjn+AmpnPBGw6wj/SZsb9/JftdUmkB3paOS5M/16BM/W7XxcVbENUNAQ0dFENJOIMkQ01rFtayL6jG//lsiY7UdEO/Dvc4noDuI9ChH1IqJ3iOgH/rcnLye+31wi+oaIti/6fYnw5iz77TisF944fw9XVI77fNJn/mWbIfX46JJ9bPsJZ7SXndXy0fh3HHYfTW7ceex2nothBR1cmy93wItTliEgESHh4Yj94A97B7rOlKu811B/6rc748NL3Oc5b19/k5QXaebuWK1BQm7n6owpROWjCYJbEVVpNO7jjhk7BG+cvwf2cax546f5q36Pk3YdhsO2Va/HkyuqBLmy6ez6w7Yy63bTUVvDj31G9cO4Tbz9ZvJ9iujCnlVGKPbr5++BDy/ZG29fuKdn9Kpf/QVVUcN0NrhnZaDw9EJTKo1mBoAjAHwkFxJRBMCTAM5ijG0JYG9Y+dbugZFBeiT/N56XXw5gEmNsJIBJ/DsAHCTtewY/vqioos682GJgbU6Tt0TnUx0LY+Pe9hGSGK1kixzJ5oPJxUfjpCIaxvA+Xml2cuv1nNf2swhm64C9NJphfaoDRfb0qfEeRdbEIxjauxrOLtY5iz8oqbRxp7KPRphdcu30O6PRmDPVpbJAGpVjF7dGY9c05GzFWwx0h0yLw1XhwUoTHFGg0OsgqN8PozAaJlRJASAVAaIORw2oNevoxPTRgLC21eju+nLtpa4yiqG9q7FZ/x6dMgdWxIyuvj2ZLthvlAslETSMsdmMse8Um/4PwDeMsel8v9WMsTQRDQRQyxj7nBl65uMADuPHHArgMf75MUf548zgcwD1/DxFQziFs0V4CLK9vGKOgGw6UwmxSu7o87LLW6Gakkaj6KFziTrLhaChk1bAjYfpzGUmc7+4zlVCnSGwfucD8vO3KKKu8yLFV+6SR84iNDZ3jaZTxjN+TXcH74fYRfyGziqEFKZOYz91XcUASnVpr/oUqt36mc4yzJpUG+R62aL3VJqbKl1/ZyZtV8WsTPCloNx8NJsBYET0FhF9RUSX8vJBABZL+y3mZQDQnzG2lH9eBqC/dMwij2NsENEZRDSFiKasXLky78qftOswnLXXCJy5pzrk0Em2hvPQyTvikgM3x+CelVZ6G8VYtZL7aFR5vQDZdGaVqSJobPH+0ub//m4X/COLecCPoKGTQiA5XwbvTtOd1fqPE7aw/UJepjNxvJMjtx+Ms/YK9vy8zpJvhyDS5YRChDP33AQTxgw0/Q45azS5yBnHvmlpwqYgyD0REa7+xWhM5BkfVMEAzv0Vlzd58ezdcNWELRBReOG9aiP7NQuFuI2IKWjUC+QBarOpEUTpDrBQ8eq5u+P6Q7fMGhUahD8fMtr8XBOP4I8Hj8JTvzXWmfr36Tvj9l9vm9sJO0HRwpuJ6F0AKqP9lYyxl33qszuAHWGs5jmJiKYCaAhyTcYYI6Kch3KMsfsB3A8AY8eOzXsoWBENe2ZYVZHtZRjSsxLniLkCPmY5MVrx0hwsO7//yEqefS5v32FoL+wwtBcuef4b/wp7ELTTEzPShUYoqiCHf8oY4aBW4Zl7bWIbCRKARMo7R5iXRnP5QaNw74fzglUabiGgqmcQkmnrh7riYHvG55w1mk4Yz1QTNoNqNLLf0R3ebNdosp1y0341nssReAnezkxs9jih+VFoNIxJxY7LbbdxT9cpQuRvypSf1ZjBdRgjZXG2VyW3eztlt+G49tVZ5nd5SsKuI4zQ8POfmZbTOfOlaIKGMebtRfVmMYCPGGOrAICIXgewPQy/jbxM3mAAS/jn5UQ0kDG2lJvGVvDyJQCGeBxTFmRrNypTlqrBChuxp+lMESKrarSrmhO+27PhJVCCdnliJO2Vl8k5iiQ47knRdflHnRWGrjBG5Bx1lqO5UnWsvC0fi4tKk82W6ysoXj+HqGeh5Q1gtwKY75Tz+qrINJD0m3pXrOBCsowoN9PZWwDGEFEVDwzYC8AsbhprJKJxPNrsRABCK3oFwEn880mO8hN59Nk4AA2Sia3obDGwFvtv4b9oWLbOwy4Y+AfFSxkNWyq933nkl1zVcchRP7nYxbOxHQ8DBoCz9/Y2SwnTnzNdxq92NMYLY6VcbUZ91DZ/MSu6V3UMp+2+ief1CvViy6epiUfM844aYCxR7Jypf2EeS0PnWtWgfXfIUAttHD3WGNONs621EsR0lr0Otn068fN7ms4CHi+vlxOUIPNoVIMkQ6MRkXzuY6yQ7fw5d59NO5UPsdiUKrz5cCJaDGAXABOJ6C0AYIytBXArgC8BTAPwFWNsIj/sbAAPApgLYB6AN3j5jQAOIKIfAOzPvwPA6wDm8/0f4Md3GW+cvwcePGlH332ytQvVQkwqk0gbT3GR8Ri8q451CrkFN06wRaPk0wd7HTOwrgILbpyABTdOsGXbdSI0MqePZtcRfbDgxgkYrErIqPgVj91pYyy4cQIqomFM2HqgK0DAOrYwyHWYce2B5rdxm/TGghsnuNYVOX//kThoK3UouBdF02gAl0RQ1duvE3vytJ35uZy+NeuzyNStPk3uKo3XIEFoFNmc9DcfvY3vdrlG1lLLIalMXWeVs52IAgmTzox7/nDg5pj/twn5n6DIlCQFDWPsRQAvemx7EoapzFk+BYBriTzG2GoA+ynKGYBzOl3ZIpJLNlbTcapo383tKQB+Go372KzalGoyIwq3toyKtMNHkw2X6SzHYW6hLBXO84jH6hcEEXRBOfMaOdYpqI8mqADz28/LAS93xqID9lrFMle8Xp1CD+rl86kemSvxq8ekTiZ/cdC5CMH1g3IznW1Q5KLqmnN0FNsG8dUMvTq2sUMNk1NUCt2lLE9e1a8U24YsEmCO7GeYnJSrNNrqE2yS6U5ZkkwW2uTgNygQqOYyCFObimJpNDsOdzuvVQg/4BjF0g5eVbNNdjQ1jcLgHQLv9kd2+lr8XOqF8ux4TYT202iseTTdFy1oSorRtKpjYXx2xb4B9nSPfp47axf8ZuehALyjzu48bju89vvdbWt3dCYmP1eCjtfErZ2wy1A8d9Yu+L8t3ealSRfvZX4Omg34vhN2wO8UviHRWalGoZP/uB8+vGTvQPX2ijLz0yrO2MPuO9pxWE88e6Z7AS6va8h8evm+rvXlVfRQTCS974Sxij3dDKirwOOn7oT7T9wh+86cjFKjCXy4L57zaIrQrC3TGbnKnCg1GuMI47NP/XQwgKYoiDa5ce9q9OthLDOb7QVytu8dh/UyG7eXRlMVi7gWGcu66FoJ2rwcdeaV6n5E3xqzw1T4sZVUxyMYrZh5LlAJ3f61FXzWf3BEOntrUOC9byhE2EYKY92sfw/lJD2BXye0UX2lyw+kMseMUIQK1+SQxWDPzfpiYJ2/lmmvg/U5bGoaKtNR4FNmfd7FHEAFWZFVufxGSNZovO+/G8sZLWhKiTXbn5nNL+q5QJG3Ocb0CeSwelG2Rl3IzABBUeX6UhGWfDhBR4HKaB+ogw9ypZWnge9fKwYL8hi2NBRiwl9gPEJ35YGP6vfP1U8lXconM0BhUL9n2c/utY+fMDEj0gLXbv1Dr0dTQmzzFEKEC/ffDAeM7o+D7/jYc19V5yUady6r5OUSWm2WBT99XghBma3jj0hmmKCjQD/Bmc86I7I/ZdO+NTht9+E4eddhZr2A3Jy8hRZKp+w2DEsb2vDk5wsBACeMG4oJWw/Er+//vMBXsnD+iqrILZn7TxiLpyb/5DkpU4UQ6l6aWMhHc8oH+TQ201kOwiGbHzEXje6Kg0Zhx+HePsd7j98e7Un/FT1LgRY0JcTZ2futomju6bMgWC6r5GUb3ao25/vuBq2W0GiyDXTl5bFznb2uqlc+93X0WGsucChkpF4x6+GjfWarS6GoikXwl8PGmILm+sO2wnfLmtTX7uzFvIIBpJtSXWPj3lWuDAhB8Ux2WgwfDdwTib0mYKqDaPzn0fge7ODMLOmRxm9V1HSOeaNNZyVEtKsgAsLPHGOdJ/i1s2s0Xa/IZ8wcWzloNFK5n9aiNlkY5GM6C9Jf5CY8im9oK/aEPnd4s/y5sPdXnU2jKejV+Lnz/AFDJGfEVvhoOlOp9QQtaEpILn4Qp4N59MBaM8266ChzeZm9+nIxq171Tp27T/B164Ncy4kqx5YK4aPJzXTmxmuCqBde67N7Xasz+caKgdd8l07joRkesb01+75vDot2+XHE9oP8I7cKchVA1f3LJlbnq3bqbsM9zxQNh/DLbYx1cnZwZLeQz1UKH02Piq4xamlBU0KE3z+IfHCGzL5+/h74gC+Alo/pzEtjueiAzbDgxgnK7X6mvUKQDuijMSOYHKazXBG/VtBzXHLgKNMP44ffkg6edekCmeSVn6tg53ec+YDR/c2MED0qvCPqcuHWY7bFjz4z4M13yuccuTQZeVfl8uf8758OGY0FN6rr1bsmjj0364sFN07wWLwsgFmtSHx7zYFdch0taEpIyMcc5sTP7i9egHQutrMyJBM06iyPORl+++ZlOvO1nRl/cnkcXSJo+N+unEPV1QSxEuQT/MFPbuL1uFTPsSYebBnlUkR6dhVa0JQQyxwWxEcj9nVvq+Hq7+Y+M8tLSdBOdGR/o/7Z1HmRdDPDWLAUNMZWz3oVuuMNajqzRWV1gZlNaDT5+hqyn78op82rDn7vVK73L6Li6itjZhnLwd7Vu9rfbCjmQPUrkHkxH8TS0cVCR52VEL+QZS9U+w6sq8QzZ4zD1h7rWJSKmngEzR2pwPv//cgxOG6njV2TD52IjiKVZoFS0HjDNagchlvBBgV5PNguwEyh77H91zsOyRrVpKKcUqgECWLxWoZCRn7MV00YjfFbDlSmDcqmhTx+6k7YRsperuLMPUdg9MBa7L25f7b3fHjv4r2yDqRePXd3DKirKPi1ZbSgKSnBO6RsIzV7SvfyYNsh9fhk7qrA+1fFIthlRPb7EB1FOsOCBwOoos5EapE8huJ+R4QCPtau7phFp+jV8QzvU43hfXLLhmC/QOlFTRBlJZfnTUSoiIax+8g+edVnz836Zq9PiIoiZABgE6VPyI7XQmuFRJvOSkhuTsnSv8TlgsjunMqwwGYvZdQZ/1toU1IuYetmXbokGMD467zd7pQ9OMh7UojnnS1DgcaO1mjKgEDBAHnNzehazthzBJasbcP7361EQ1vSLC+0/0GMSNMZ1inxu2nfGhy388Y4dbdh2P/WjwIdc/7+m6GhLWmbsOkk6IRN5vG5WFiCpkg+mqKcNTdCAd6TIKazbYfU41djh7iSsZ6330iMG94Li9e2AVBkQyjj97OUaI2mhMi5zrIRJCNwqamrjOKfv96u6LH5Ycl0Zp+x6d2BKHN/hQh/PXwMNu0XPIiiV3UM//z1dp4TBuVq5OR764LHaqVnsZcXI11LqQhShyAaTSQcwt+P2hrDHKbEiw7YDLtump8ZbUNGC5oSYkUnBdk397kZpaLYHY4wnaUzwYMBStEHZhtAdLmPRmg0jo62s6azUk44dGJl0PC+p7zDmyXKecBXjmhBUwYEec8H8MzAx/iYbJzsv0X/fKvky26bBgs82G8Lw8G53RD3bOjOcNi2gwAAw/tWl0Xn5iTo/KiuCG8e2rvKTECZLT1L3tNLyughOKty1A6DXftkmzeVbaE8ANiWt2nnmkkb1Rc3emt9RftoSkgu5rC6qijm/fXgnPJVPXDiDgXXgOb/9eDAHcu+o/rhxF2GdToNv5Ojxw7BEdsPRjhEWNOSCHRMV3aG+WRvLtYA+f2L9zY/bwgTNuWsDKKtPj91sW0fv/YYtH1vPqAH5v31YNe5etfEMe+vB2PEH1/PvfLdGC1o1iNy7bCJgq1AmQu5ROwQqOBCRiDOG/T0XSpo8sneXKS6qJ5XsRKmlsMKkc6lN1T4tclc2rfXeYrV5tdntOmshOSTE2t9YJM+Rux+PFr85iWHs3a2nxMrZHaWco0QtHK7Fef85dC9BnmnRvTtxFwhTV5ojaYMcL4UL5y9K/pkSVtRztx53HaYsmCNueJkUSH5o0/UWZZu8OnTx2GTAnVAVpBHeUmadMBlGHKlrJYizmKOfvjksZ7LhGuKhxY0Zcj2GxfWed7V1FZEse+o4gQiOAk8Os+yX5CMBEERJqTckmoWXyhZSUuLfqmSkU2j6ap2qbGjTWclJC+nscZGOfgFnORjOuuKFuC1KmShKIfsFaWvgUZFSQQNER1NRDOJKENEY6Xy3xDRNOlfhoi25dt2IKJviWguEd1B/G0hol5E9A4R/cD/9uTlxPebS0TfENH2pbhXP8qxk1zfkEfnfj6hrvylrWv5i48bj9gaOw3rhZ2G98LFB2xe7Gpho/pKHLhlf9x53Ha28oKNc8qgOeey9MZVE7bAJQcW53c/dbfhuO1X2xTl3OsjpTKdzQBwBID75ELG2FMAngIAIhoD4CXG2DS++R4ApwOYDOB1AOMBvAHgcgCTGGM3EtHl/PtlAA4CMJL/25kfv3NR7ypHcpmwqVEjj6I915FH1wp1ChjkMXqjWvznrF26oEYG4RDhvhPGem7vrEZSBnImJz/Rb/fYpGj1+NMho4t27vWRkmg0jLHZjLHvsux2LIBnAICIBgKoZYx9zgw70+MADuP7HQrgMf75MUf548zgcwD1/DxlQz7JFzV25I6lT01hosY6S9DszeVGuQUv5APp0VtZUs4+ml8BeJp/HgRAnnW1mJcBQH/G2FL+eRmA/tIxizyOsUFEZxDRFCKasnLlykLUPRC1fHnbw7ZTVksTAFnQjBrgXi/E3K8L6iIQy/WKzAjdnY35+kHjtxqQZc/i46eV7a5zlJWMopnOiOhdAKqWdyVj7OUsx+4MoJUxNiOXazLGGBHlPJZhjN0P4H4AGDt2bJeNharjEcy89kBURoMt9apxI3csfos3NbUHX4CtswzrU40Z1x6I6lhhn+uc68dj1NVvFvScMvmazgb1rCzK/eaDpU1ar/Gc68cjmc7o96yEFE3QMMb278Thv4alzQDAEgBy0qLBvAwAlhPRQMbYUm4aWyEdM8TjmLLBLwuwJjjRsH8nubqlo4tqYlBThOdaUaYdJaE495sPKl9cRTRctr/dhkLZmc6IKATgGHD/DABw01gjEY3j0WYnAhBa0SsATuKfT3KUn8ijz8YBaJBMbJpughjBDunpv/yzjvDzphf3bdVV5rdufDn+tNrtWV6UZBhCRIcDuBNAXwATiWgaY+xAvnlPAIsYY/Mdh50N4FEAlTCizd7g5TcC+A8RnQbgJxhCCjAi0w4GMBdAK4BTinM3mlISCYdw3wk7YLss67Ifu+MQREOEy1/4tmsqth5x+h6boHd1TJnpeH2jHIWepkSChjH2IoAXPbZ9AGCconwKgK0U5asB7KcoZwDO6WxdNeXPgVtmd0JHwiH8eqeNtaBREA2H8KsdN877+HLUFrVCU16UnelMo9Fo8qX8RJ4G0LnONjjO228kmtqTpa5GyTh77xFI5ZKErMw4eMwA7L5p31JXo+zRaZ3KCy1oNjAuOmCzUlehpFw6flSpq9Ap7v7NDqWuQllThlY8DbTpTKPRdCuC5zrTdB1a0Gg0mm5DuS46t6GjBY1Go+l2aDlTXmhBo9Foug3aRVOeaEGj0Wi6H9p2VlboqLMNnGfPGIdQd17bV1N2PHLKjujrs3ZQZyjHyaMaLWg2eHbepHepq6DZwNhn8+Ivn6D1mfJCm840Gk23Qesz5YnWaDSaDZAL998MXy5YU+pqFA3toikvtKDRaDZAzt9/ZKmrUBS0i6Y80aYzjUbT7WDaS1NWaEGj0Wi6DfkuR60pLlrQaDSabof20ZQXWtBoNJpug/bRlCda0Gg0mm6H1mjKCy1oNBpNt0PLmfJCCxqNRtNtsJYJ0KKmnNCCRqPRdBt01Fl5ogWNRqPpNgztXQUAuKCbTkhdX9GZATQaTbehOh7BghsnlLoaGgdao9FoNBpNUdGCRqPRaDRFpSSChoiOJqKZRJQhorFSeZSIHiOib4loNhFdIW0bT0TfEdFcIrpcKh9ORJN5+bNEFOPlcf59Lt8+rEtvUqPRaDQASqfRzABwBICPHOVHA4gzxsYA2AHAmUQ0jIjCAP4F4CAAowEcS0Sj+TF/B3AbY2xTAGsBnMbLTwOwlpffxvfTaDQaTRdTEkHDGJvNGPtOtQlANRFFAFQCSABoBLATgLmMsfmMsQSAZwAcSsa6rfsCeJ4f/xiAw/jnQ/l38O37kV7nVaPRaLqccos6ex6GgFgKoArAhYyxNUQ0CMAiab/FAHYG0BvAOsZYSiofxD+bxzDGUkTUwPdf5bwoEZ0B4AwA2HjjjQt9TxpNt+TVc3fHtEVrS10NzXpA0QQNEb0LYIBi05WMsZc9DtsJQBrARgB6AviYn6eoMMbuB3A/AIwdO1ZPKdZoAjBmcB3GDK4rdTU06wFFEzSMsf3zOOw4AG8yxpIAVhDR/wCMhaGZDJH2GwxgCYDVAOqJKMK1GlEO/ncIgMXcFFfH99doNBpNF1Ju4c0LYfhcQETVAMYBmAPgSwAjeYRZDMCvAbzCjIRG7wM4ih9/EgChLb3Cv4Nvf4/pBEgajUbT5ZQqvPlwIloMYBcAE4noLb7pXwBqiGgmDOHyCGPsG66tnAvgLQCzAfyHMTaTH3MZgIuIaC4MH8xDvPwhAL15+UUAzJBojUaj0XQdpAf5dsaOHcumTJlS6mpoNBrNegURTWWMjVVtKzfTmUaj0Wi6GVrQaDQajaaoaEGj0Wg0mqKiBY1Go9FoiooOBnBARCsB/JTn4X2gyDzQzdH3vGGg73nDoDP3PJQx1le1QQuaAkJEU7yiLror+p43DPQ9bxgU65616Uyj0Wg0RUULGo1Go9EUFS1oCsv9pa5ACdD3vGGg73nDoCj3rH00Go1GoykqWqPRaDQaTVHRgkaj0Wg0RUULmgJBROOJ6DsimktE3SZTNBENIaL3iWgWEc0kovN5eS8ieoeIfuB/e/JyIqI7+O/wDRFtX9o7yA8iChPR10T0Gv8+nIgm8/t6li9XASKK8+9z+fZhJa14nhBRPRE9T0RziGg2Ee2yATzjC3mbnkFETxNRRXd8zkT0MBGtIKIZUlnOz5aITuL7/0BEJ6mu5YUWNAWAiMIwljg4CMBoAMcS0ejS1qpgpABczBgbDWN9oHP4vV0OYBJjbCSASbCWYTgIwEj+7wwA93R9lQvC+TCWpBD8HcBtjLFNAawFcBovPw3AWl5+G99vfeR2GIsOjgKwDYx777bPmC8Pfx6AsYyxrQCEYaxz1R2f86MAxjvKcnq2RNQLwJ8B7AxjJeQ/C+EUCMaY/tfJfzDW1XlL+n4FgCtKXa8i3evLAA4A8B2AgbxsIIDv+Of7ABwr7W/ut778g7FS6yQYi/C9BoBgzJaOOJ83jDWSduGfI3w/KvU95Hi/dQB+dNa7mz/jQTBW7u3Fn9trAA7srs8ZwDAAM/J9tgCOBXCfVG7bL9s/rdEUBtFoBYt5WbeCmwu2AzAZQH/G2FK+aRmA/vxzd/gt/gngUgAZ/r03gHXMWIAPsN+Teb98ewPff31iOICVAB7h5sIH+Qq33fYZM8aWALgZxqq+S2E8t6no3s9ZJtdn26lnrgWNJhBEVAPgvwAuYIw1ytuYMcTpFnHyRPQLACsYY1NLXZcuJAJgewD3MMa2A9ACx4q03ekZAwA3+xwKQ8huBKAabvPSBkFXPFstaArDEgBDpO+DeVm3gIiiMITMU4yxF3jxciIayLcPBLCCl6/vv8VuAH5JRAsAPAPDfHY7gHoiivB95Hsy75dvrwOwuisrXAAWA1jMGJvMvz8PQ/B012cMAPsD+JExtpIxlgTwAoxn352fs0yuz7ZTz1wLmsLwJYCRPGIlBsOp+EqJ61QQiIgAPARgNmPsVmnTKwBE5MlJMHw3ovxEHr0yDkCDpKKXPYyxKxhjgxljw2A8x/cYY78B8D6Ao/huzvsVv8NRfP/1auTPGFsGYBERbc6L9gMwC930GXMWAhhHRFW8jYt77rbP2UGuz/YtAP9HRD25Nvh/vCwYpXZSdZd/AA4G8D2AeQCuLHV9Cnhfu8NQq78BMI3/OxiGfXoSgB8AvAugF9+fYETgzQPwLYyonpLfR573vjeA1/jnTQB8AWAugOcAxHl5Bf8+l2/fpNT1zvNetwUwhT/nlwD07O7PGMC1AOYAmAHgCQDx7vicATwNww+VhKG9npbPswVwKr//uQBOyaUOOgWNRqPRaIqKNp1pNBqNpqhoQaPRaDSaoqIFjUaj0WiKihY0Go1GoykqWtBoNBqNpqhoQaPRFBkiShPRNOmfb3ZvIjqLiE4swHUXEFGfzp5Ho+ksOrxZoykyRNTMGKspwXUXwJgHsaqrr63RyGiNRqMpEVzjuImIviWiL4hoU15+DRH9gX8+j4y1gL4homd4WS8ieomXfU5EW/Py3kT0Nl9j5UEYk+/EtY7n15hGRPfxpS00mi5BCxqNpvhUOkxnv5K2NTDGxgC4C0bWaCeXA9iOMbY1gLN42bUAvuZlfwTwOC//M4BPGGNbAngRwMYAQERbAPgVgN0YY9sCSAP4TSFvUKPxI5J9F41G00naeAev4mnp722K7d8AeIqIXoKRGgYw0gIdCQCMsfe4JlMLYE8AR/DyiUS0lu+/H4AdAHxppPVCJawkihpN0dGCRqMpLczjs2ACDAFyCIAriWhMHtcgAI8xxq7I41iNptNo05lGU1p+Jf39TN5ARCEAQxhj7wO4DEZq+hoAH4ObvohobwCrmLFG0EcAjuPlB8FIjAkYyROPIqJ+fFsvIhpavFvSaOxojUajKT6VRDRN+v4mY0yEOPckom8AdMBYLlcmDOBJIqqDoZXcwRhbR0TXAHiYH9cKK937tQCeJqKZAD6FkQofjLFZRHQVgLe58EoCOAfATwW+T41GiQ5v1mhKhA4/1mwoaNOZRqPRaIqK1mg0Go1GU1S0RqPRaDSaoqIFjUaj0WiKihY0Go1GoykqWtBoNBqNpqhoQaPRaDSaovL/yyle6ZA+nPoAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customised PPO Model"
      ],
      "metadata": {
        "id": "HvM592Xfjd_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ppo_torch"
      ],
      "metadata": {
        "id": "CmQ7qaJfjxzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions.categorical import Categorical\n",
        "\n",
        "class PPOMemory:\n",
        "  def __init__(self, batch_size):\n",
        "    self.states = []\n",
        "    self.probs = []\n",
        "    self.vals = []\n",
        "    self.actions = []\n",
        "    self.rewards = []\n",
        "    self.dones = []\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def generate_batches(self):\n",
        "    n_states = len(self.states)\n",
        "    batch_start = np.arange(0, n_states, self.batch_size)\n",
        "    indices = np.arange(n_states, dtype=np.int64)\n",
        "    np.random.shuffle(indices)\n",
        "    batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
        "    return np.array(self.states),\\\n",
        "                np.array(self.actions),\\\n",
        "                np.array(self.probs),\\\n",
        "                np.array(self.vals),\\\n",
        "                np.array(self.rewards),\\\n",
        "                np.array(self.dones),\\\n",
        "                batches\n",
        "\n",
        "  def store_memory(self, state, action, probs, vals, reward, done):\n",
        "    self.states.append(state)\n",
        "    self.actions.append(action)\n",
        "    self.probs.append(probs)\n",
        "    self.vals.append(vals)\n",
        "    self.rewards.append(reward)\n",
        "    self.dones.append(done)\n",
        "\n",
        "  def clear_memory(self):\n",
        "    self.states = []\n",
        "    self.probs = []\n",
        "    self.actions = []\n",
        "    self.rewards = []\n",
        "    self.dones = []\n",
        "    self.vals = []"
      ],
      "metadata": {
        "id": "zin1tZpgjv91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActorNetwork(nn.Module):\n",
        "  def __init__(self, n_actions, input_dims, alpha, fc1_dims=256, fc2_dims=256, chkpt_dir='tmp/ppo'):\n",
        "    super(ActorNetwork, self).__init__()\n",
        "    self.checkpoint_file = os.path.join(chkpt_dir, 'actor_torch_ppo')\n",
        "    self.actor = nn.Sequential(\n",
        "                nn.Linear(*input_dims, fc1_dims),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(fc1_dims, fc2_dims),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(fc2_dims, n_actions),\n",
        "                nn.Softmax(dim=-1)\n",
        "    )\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
        "    self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "    self.to(self.device)\n",
        "\n",
        "  def forward(self, state):\n",
        "    dist = self.actor(state)\n",
        "    dist = Categorical(dist)  \n",
        "    return dist\n",
        "\n",
        "  def save_checkpoint(self):\n",
        "    T.save(self.state_dict(), self.checkpoint_file)\n",
        "\n",
        "  def load_checkpoint(self):\n",
        "    self.load_state_dict(T.load(self.checkpoint_file))"
      ],
      "metadata": {
        "id": "MLn2B7TsjtlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CriticNetwork(nn.Module):\n",
        "  def __init__(self, input_dims, alpha, fc1_dims=256, fc2_dims=256, chkpt_dir='tmp/ppo'):\n",
        "    super(CriticNetwork, self).__init__()\n",
        "    self.checkpoint_file = os.path.join(chkpt_dir, 'critic_torch_ppo')\n",
        "    self.critic = nn.Sequential(\n",
        "                nn.Linear(*input_dims, fc1_dims),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(fc1_dims, fc2_dims),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(fc2_dims, 1)\n",
        "    )\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
        "    self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "    self.to(self.device)\n",
        "\n",
        "  def forward(self, state):\n",
        "    value = self.critic(state)\n",
        "    return value\n",
        "\n",
        "  def save_checkpoint(self):\n",
        "    T.save(self.state_dict(), self.checkpoint_file)\n",
        "\n",
        "  def load_checkpoint(self):\n",
        "    self.load_state_dict(T.load(self.checkpoint_file))"
      ],
      "metadata": {
        "id": "7nV_i7PKjrjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "  def __init__(self, n_actions, input_dims, gamma=0.99, alpha=0.0003, gae_lambda=0.95, policy_clip=0.2, batch_size=64, n_epochs=10):\n",
        "    self.gamma = gamma\n",
        "    self.policy_clip = policy_clip\n",
        "    self.n_epochs = n_epochs\n",
        "    self.gae_lambda = gae_lambda\n",
        "    self.actor = ActorNetwork(n_actions, input_dims, alpha)\n",
        "    self.critic = CriticNetwork(input_dims, alpha)\n",
        "    self.memory = PPOMemory(batch_size)\n",
        "       \n",
        "  def remember(self, state, action, probs, vals, reward, done):\n",
        "    self.memory.store_memory(state, action, probs, vals, reward, done)\n",
        "\n",
        "  def save_models(self):\n",
        "    print('... saving models ...')\n",
        "    self.actor.save_checkpoint()\n",
        "    self.critic.save_checkpoint()\n",
        "\n",
        "  def load_models(self):\n",
        "    print('... loading models ...')\n",
        "    self.actor.load_checkpoint()\n",
        "    self.critic.load_checkpoint()\n",
        "\n",
        "  def choose_action(self, observation):\n",
        "    state = T.tensor([observation], dtype=T.float).to(self.actor.device)\n",
        "    dist = self.actor(state)\n",
        "    value = self.critic(state)\n",
        "    action = dist.sample()\n",
        "    probs = T.squeeze(dist.log_prob(action)).item()\n",
        "    action = T.squeeze(action).item()\n",
        "    value = T.squeeze(value).item()\n",
        "    return action, probs, value\n",
        "\n",
        "  def learn(self):\n",
        "    for _ in range(self.n_epochs):\n",
        "      state_arr, action_arr, old_prob_arr, vals_arr,\\\n",
        "      reward_arr, dones_arr, batches = \\\n",
        "      self.memory.generate_batches()\n",
        "      values = vals_arr\n",
        "      advantage = np.zeros(len(reward_arr), dtype=np.float32)\n",
        "      \n",
        "      for t in range(len(reward_arr)-1):\n",
        "        discount = 1\n",
        "        a_t = 0\n",
        "        for k in range(t, len(reward_arr)-1):\n",
        "          a_t += discount*(reward_arr[k] + self.gamma*values[k+1]*\\\n",
        "                          (1-int(dones_arr[k])) - values[k])\n",
        "          discount *= self.gamma*self.gae_lambda\n",
        "        advantage[t] = a_t\n",
        "      advantage = T.tensor(advantage).to(self.actor.device)\n",
        "\n",
        "      values = T.tensor(values).to(self.actor.device)\n",
        "      for batch in batches:\n",
        "        states = T.tensor(state_arr[batch], dtype=T.float).to(self.actor.device)\n",
        "        old_probs = T.tensor(old_prob_arr[batch]).to(self.actor.device)\n",
        "        actions = T.tensor(action_arr[batch]).to(self.actor.device)\n",
        "        dist = self.actor(states)\n",
        "        critic_value = self.critic(states)\n",
        "        critic_value = T.squeeze(critic_value)\n",
        "        new_probs = dist.log_prob(actions)\n",
        "        prob_ratio = new_probs.exp() / old_probs.exp()\n",
        "        #prob_ratio = (new_probs - old_probs).exp()\n",
        "        weighted_probs = advantage[batch] * prob_ratio\n",
        "        weighted_clipped_probs = T.clamp(prob_ratio, 1-self.policy_clip,\n",
        "                        1+self.policy_clip)*advantage[batch]\n",
        "        actor_loss = -T.min(weighted_probs, weighted_clipped_probs).mean()\n",
        "        returns = advantage[batch] + values[batch]\n",
        "        critic_loss = (returns-critic_value)**2\n",
        "        critic_loss = critic_loss.mean()\n",
        "        total_loss = actor_loss + 0.5*critic_loss\n",
        "        self.actor.optimizer.zero_grad()\n",
        "        self.critic.optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        self.actor.optimizer.step()\n",
        "        self.critic.optimizer.step()\n",
        "        \n",
        "    self.memory.clear_memory()  "
      ],
      "metadata": {
        "id": "pGCpMb_JjpW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_learning_curve(x, scores, figure_file):\n",
        "  running_avg = np.zeros(len(scores))\n",
        "  for i in range(len(running_avg)):\n",
        "    running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
        "  plt.plot(x, running_avg)\n",
        "  plt.title('Running average of previous 100 scores')\n",
        "  plt.savefig(figure_file)"
      ],
      "metadata": {
        "id": "0ESZjlzGjnRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from ppo_torch import Agent\n",
        "from utils import plot_learning_curve\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    env = gym.make('CartPole-v0')\n",
        "    N = 20\n",
        "    batch_size = 5\n",
        "    n_epochs = 4\n",
        "    alpha = 0.0003\n",
        "    agent = Agent(n_actions=env.action_space.n, batch_size=batch_size, \n",
        "                    alpha=alpha, n_epochs=n_epochs, \n",
        "                    input_dims=env.observation_space.shape)\n",
        "    n_games = 300\n",
        "\n",
        "    figure_file = 'plots/cartpole.png'\n",
        "\n",
        "    best_score = env.reward_range[0]\n",
        "    score_history = []\n",
        "\n",
        "    learn_iters = 0\n",
        "    avg_score = 0\n",
        "    n_steps = 0\n",
        "\n",
        "    for i in range(n_games):\n",
        "        observation = env.reset()\n",
        "        done = False\n",
        "        score = 0\n",
        "        while not done:\n",
        "            action, prob, val = agent.choose_action(observation)\n",
        "            observation_, reward, done, info = env.step(action)\n",
        "            n_steps += 1\n",
        "            score += reward\n",
        "            agent.remember(observation, action, prob, val, reward, done)\n",
        "            if n_steps % N == 0:\n",
        "                agent.learn()\n",
        "                learn_iters += 1\n",
        "            observation = observation_\n",
        "        score_history.append(score)\n",
        "        avg_score = np.mean(score_history[-100:])\n",
        "\n",
        "        if avg_score > best_score:\n",
        "            best_score = avg_score\n",
        "            agent.save_models()\n",
        "\n",
        "        print('episode', i, 'score %.1f' % score, 'avg score %.1f' % avg_score,\n",
        "                'time_steps', n_steps, 'learning_steps', learn_iters)\n",
        "    x = [i+1 for i in range(len(score_history))]\n",
        "    plot_learning_curve(x, score_history, figure_file)"
      ],
      "metadata": {
        "id": "dAC0XRx9jjup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "seukdM_xj2Xq"
      }
    }
  ]
}